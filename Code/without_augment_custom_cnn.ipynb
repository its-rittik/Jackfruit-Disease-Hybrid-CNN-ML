{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3562b75",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a99f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2195 files belonging to 6 classes.\n",
      "Using 1756 files for training.\n",
      "Found 2195 files belonging to 6 classes.\n",
      "Using 439 files for validation.\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30s/step - accuracy: 0.4000 - loss: 1.5029 \n",
      "Epoch 1: val_accuracy improved from None to 0.00000, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m896s\u001b[0m 32s/step - accuracy: 0.4710 - loss: 1.3375 - val_accuracy: 0.0000e+00 - val_loss: 1.8443 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38s/step - accuracy: 0.5564 - loss: 1.0974 \n",
      "Epoch 2: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1101s\u001b[0m 39s/step - accuracy: 0.5598 - loss: 1.0944 - val_accuracy: 0.0000e+00 - val_loss: 2.2533 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - accuracy: 0.5485 - loss: 1.0704 \n",
      "Epoch 3: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m820s\u001b[0m 29s/step - accuracy: 0.5598 - loss: 1.0576 - val_accuracy: 0.0000e+00 - val_loss: 2.6459 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34s/step - accuracy: 0.5556 - loss: 1.0180 \n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m995s\u001b[0m 35s/step - accuracy: 0.5746 - loss: 0.9994 - val_accuracy: 0.0000e+00 - val_loss: 2.3192 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34s/step - accuracy: 0.5985 - loss: 0.9571 \n",
      "Epoch 5: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1005s\u001b[0m 36s/step - accuracy: 0.6071 - loss: 0.9218 - val_accuracy: 0.0000e+00 - val_loss: 2.6478 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67s/step - accuracy: 0.6364 - loss: 0.8892  \n",
      "Epoch 6: val_accuracy improved from 0.00000 to 0.02278, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1925s\u001b[0m 69s/step - accuracy: 0.6327 - loss: 0.8855 - val_accuracy: 0.0228 - val_loss: 2.2996 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32s/step - accuracy: 0.6605 - loss: 0.8882 \n",
      "Epoch 7: val_accuracy did not improve from 0.02278\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m966s\u001b[0m 33s/step - accuracy: 0.6669 - loss: 0.8668 - val_accuracy: 0.0000e+00 - val_loss: 2.4697 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34s/step - accuracy: 0.6438 - loss: 0.8605 \n",
      "Epoch 8: val_accuracy did not improve from 0.02278\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m995s\u001b[0m 36s/step - accuracy: 0.6595 - loss: 0.8329 - val_accuracy: 0.0000e+00 - val_loss: 1.9400 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42s/step - accuracy: 0.6655 - loss: 0.8256 \n",
      "Epoch 9: val_accuracy improved from 0.02278 to 0.09567, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1214s\u001b[0m 43s/step - accuracy: 0.6697 - loss: 0.8077 - val_accuracy: 0.0957 - val_loss: 1.7326 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - accuracy: 0.6904 - loss: 0.7841 \n",
      "Epoch 10: val_accuracy did not improve from 0.09567\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m865s\u001b[0m 31s/step - accuracy: 0.6771 - loss: 0.7966 - val_accuracy: 0.0023 - val_loss: 2.1117 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24s/step - accuracy: 0.6859 - loss: 0.7830 \n",
      "Epoch 11: val_accuracy improved from 0.09567 to 0.12301, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 25s/step - accuracy: 0.6828 - loss: 0.7822 - val_accuracy: 0.1230 - val_loss: 1.7574 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - accuracy: 0.6921 - loss: 0.7717 \n",
      "Epoch 12: val_accuracy did not improve from 0.12301\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m850s\u001b[0m 30s/step - accuracy: 0.6936 - loss: 0.7601 - val_accuracy: 0.1002 - val_loss: 3.3227 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23s/step - accuracy: 0.6897 - loss: 0.7392 \n",
      "Epoch 13: val_accuracy improved from 0.12301 to 0.23690, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 24s/step - accuracy: 0.6959 - loss: 0.7302 - val_accuracy: 0.2369 - val_loss: 3.0242 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32s/step - accuracy: 0.7006 - loss: 0.7380 \n",
      "Epoch 14: val_accuracy improved from 0.23690 to 0.26196, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m916s\u001b[0m 33s/step - accuracy: 0.7187 - loss: 0.7061 - val_accuracy: 0.2620 - val_loss: 2.0583 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25s/step - accuracy: 0.7032 - loss: 0.7259 \n",
      "Epoch 15: val_accuracy did not improve from 0.26196\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 27s/step - accuracy: 0.7067 - loss: 0.7225 - val_accuracy: 0.0888 - val_loss: 2.5628 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - accuracy: 0.7310 - loss: 0.6927 \n",
      "Epoch 16: val_accuracy did not improve from 0.26196\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m777s\u001b[0m 28s/step - accuracy: 0.7289 - loss: 0.6874 - val_accuracy: 0.1868 - val_loss: 2.6413 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32s/step - accuracy: 0.7209 - loss: 0.7101 \n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.26196\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m952s\u001b[0m 33s/step - accuracy: 0.7289 - loss: 0.6892 - val_accuracy: 0.0137 - val_loss: 5.4309 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - accuracy: 0.7254 - loss: 0.6785 \n",
      "Epoch 18: val_accuracy did not improve from 0.26196\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m871s\u001b[0m 31s/step - accuracy: 0.7403 - loss: 0.6472 - val_accuracy: 0.1686 - val_loss: 2.8915 - learning_rate: 2.5000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.7619 - loss: 0.5815 \n",
      "Epoch 19: val_accuracy did not improve from 0.26196\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 20s/step - accuracy: 0.7603 - loss: 0.5897 - val_accuracy: 0.2210 - val_loss: 2.5648 - learning_rate: 2.5000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48s/step - accuracy: 0.7699 - loss: 0.5739 \n",
      "Epoch 20: val_accuracy improved from 0.26196 to 0.49431, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1343s\u001b[0m 49s/step - accuracy: 0.7699 - loss: 0.5734 - val_accuracy: 0.4943 - val_loss: 1.5470 - learning_rate: 2.5000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping final epoch weights (no improvement over last OR no checkpoint).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full model (.h5): D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_full.h5\n",
      "Saved weights (.weights.h5): D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn.weights.h5\n",
      "Saved feature extractor (.h5): D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_feature_extractor.h5\n",
      "Saved meta: D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_meta.json\n",
      "WARNING:tensorflow:From c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "os.environ.pop(\"XLA_FLAGS\", None)\n",
    "tf.config.set_soft_device_placement(True)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(2)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(2)\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "for g in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "        print(\"Mixed precision ON\")\n",
    "    except Exception:\n",
    "        print(\"Mixed precision not enabled; continuing in float32.\")\n",
    "\n",
    "\n",
    "OUT_DIR   = r'D:\\Research\\Custom CNN\\Without Augmented'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "data_root = r'D:\\Research\\Custom CNN\\Without Augmented\\Original Image'  # class subfolders\n",
    "IMG_SIZE  = (224, 224)\n",
    "BATCH     = 64\n",
    "VAL_SPLIT = 0.2\n",
    "SEED      = 42\n",
    "\n",
    "FULL_MODEL_H5      = os.path.join(OUT_DIR, \"custom_cnn_full.h5\")\n",
    "WEIGHTS_H5         = os.path.join(OUT_DIR, \"custom_cnn.weights.h5\")\n",
    "FEAT_EXTRACTOR_H5  = os.path.join(OUT_DIR, \"custom_cnn_feature_extractor.h5\")\n",
    "META_JSON          = os.path.join(OUT_DIR, \"custom_cnn_meta.json\")\n",
    "CKPT_WEIGHTS       = os.path.join(OUT_DIR, \"custom_cnn_best.weights.h5\")\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_root, labels=\"inferred\", label_mode=\"int\",\n",
    "    image_size=IMG_SIZE, batch_size=BATCH,\n",
    "    validation_split=VAL_SPLIT, subset=\"training\", seed=SEED, shuffle=True\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_root, labels=\"inferred\", label_mode=\"int\",\n",
    "    image_size=IMG_SIZE, batch_size=BATCH,\n",
    "    validation_split=VAL_SPLIT, subset=\"validation\", seed=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "def norm(x, y):\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    return x, y\n",
    "\n",
    "train_ds = train_ds.map(norm, num_parallel_calls=2).prefetch(2)\n",
    "val_ds   = val_ds.map(norm,   num_parallel_calls=2).prefetch(2)\n",
    "\n",
    "\n",
    "aug = tf.keras.Sequential([\n",
    "    L.RandomFlip(\"horizontal\"),\n",
    "    L.RandomRotation(0.05),\n",
    "    L.RandomZoom(0.1),\n",
    "], name=\"aug\")\n",
    "\n",
    "\n",
    "def conv_block(x, filters, k=3, s=1, p=\"same\"):\n",
    "    x = L.Conv2D(filters, k, strides=s, padding=p, use_bias=False)(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_custom_cnn(input_shape=(224,224,3), n_classes=3, feature_dim=256, dropout=0.5):\n",
    "    inputs = L.Input(shape=input_shape)\n",
    "    x = aug(inputs)\n",
    "\n",
    "    x = conv_block(x, 32); x = conv_block(x, 32); x = L.MaxPooling2D(2)(x)\n",
    "    x = conv_block(x, 64); x = conv_block(x, 64); x = L.MaxPooling2D(2)(x)\n",
    "    x = conv_block(x, 128); x = conv_block(x, 128); x = L.MaxPooling2D(2)(x)\n",
    "\n",
    "    gap = L.GlobalAveragePooling2D()(x)\n",
    "    se  = L.Dense(128//4, activation=\"relu\", dtype=\"float32\")(gap)\n",
    "    se  = L.Dense(128, activation=\"sigmoid\", dtype=\"float32\")(se)\n",
    "    x   = L.Multiply()([x, L.Reshape((1,1,128))(se)])\n",
    "\n",
    "    x = L.GlobalAveragePooling2D(name=\"gap\")(x)\n",
    "    feat = L.Dense(feature_dim, activation=\"relu\", name=\"feature_dense\", dtype=\"float32\")(x)\n",
    "    x = L.Dropout(dropout)(feat)\n",
    "    outputs = L.Dense(n_classes, activation=\"softmax\", name=\"logits\", dtype=\"float32\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"custom_cnn\")\n",
    "    feat_model = Model(inputs, feat, name=\"custom_cnn_feature_extractor\")\n",
    "    return model, feat_model\n",
    "\n",
    "model, feat_model = build_custom_cnn(\n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "    n_classes=num_classes,\n",
    "    feature_dim=256,\n",
    "    dropout=0.5\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.5, patience=3, verbose=1, min_lr=1e-6),\n",
    "    ModelCheckpoint(\n",
    "        CKPT_WEIGHTS, monitor=\"val_accuracy\",\n",
    "        save_best_only=True, save_weights_only=True, verbose=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_acc = history.history.get(\"val_accuracy\", [])\n",
    "if len(val_acc) > 0 and max(val_acc) > val_acc[-1] and os.path.exists(CKPT_WEIGHTS):\n",
    "    print(f\"Loading best weights (val_acc {max(val_acc):.4f} > last {val_acc[-1]:.4f})\")\n",
    "    model.load_weights(CKPT_WEIGHTS)\n",
    "else:\n",
    "    print(\"Keeping final epoch weights (no improvement over last OR no checkpoint).\")\n",
    "\n",
    "model.save(FULL_MODEL_H5)\n",
    "model.save_weights(WEIGHTS_H5)\n",
    "feat_model.save(FEAT_EXTRACTOR_H5)\n",
    "\n",
    "with open(META_JSON, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"img_size\": IMG_SIZE,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"class_names\": class_names,\n",
    "        \"feature_dim\": 256,\n",
    "        \"epochs_trained\": int(len(history.history.get(\"loss\", []))),\n",
    "        \"best_val_accuracy\": float(max(val_acc)) if len(val_acc) else None,\n",
    "        \"last_val_accuracy\": float(val_acc[-1]) if len(val_acc) else None,\n",
    "        \"out_dir\": OUT_DIR\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"Saved full model (.h5): {FULL_MODEL_H5}\")\n",
    "print(f\"Saved weights (.weights.h5): {WEIGHTS_H5}\")\n",
    "print(f\"Saved feature extractor (.h5): {FEAT_EXTRACTOR_H5}\")\n",
    "print(f\"Saved meta: {META_JSON}\")\n",
    "\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695b4c1",
   "metadata": {},
   "source": [
    "#### Feature extraction pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load custom weights: `by_name` only supports loading legacy '.h5' or '.hdf5' files. Received: custom_cnn.weights.h5\n",
      "Proceeding with random init (features will be weak).\n",
      "Found 2195 images across 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 35/35 [01:07<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet save failed (Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\n",
      "A suitable version of pyarrow or fastparquet is required for parquet support.\n",
      "Trying to import the above resulted in these errors:\n",
      " - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n",
      " - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.); CSV still saved.\n",
      "Saved CSV: D:\\Research\\Custom CNN\\Without Augmented\\features_256d_custom.csv\n",
      "Saved meta: D:\\Research\\Custom CNN\\Without Augmented\\features_256d_custom_meta.json\n"
     ]
    }
   ],
   "source": [
    "import os, json, glob, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, BatchNormalization, Dropout,\n",
    "    GlobalAveragePooling2D, Dense\n",
    ")\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "try:\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "except Exception:\n",
    "    pass  \n",
    "\n",
    "\n",
    "USE_MIXED_PRECISION = True and bool(tf.config.list_physical_devices('GPU'))\n",
    "if USE_MIXED_PRECISION:\n",
    "    try:\n",
    "        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "        print(\"Mixed precision enabled (global_policy = 'mixed_float16').\")\n",
    "    except Exception:\n",
    "        print(\"Could not enable mixed precision; proceeding in float32.\")\n",
    "\n",
    "\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "data_root = r'D:\\Research\\Custom CNN\\Without Augmented\\Original Image'\n",
    "\n",
    "OUT_DIR = r'D:\\Research\\Custom CNN\\Without Augmented'\n",
    "\n",
    "\n",
    "class_dirs = sorted([d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d))])\n",
    "if not class_dirs:\n",
    "    raise RuntimeError(f\"No class folders found under {data_root}\")\n",
    "\n",
    "class_indices = {c: i for i, c in enumerate(class_dirs)}\n",
    "index_to_class = {i: c for c, i in class_indices.items()}\n",
    "\n",
    "BACKBONE = 'custom'\n",
    "\n",
    "CUSTOM_WEIGHTS_PATH = 'custom_cnn.weights.h5'\n",
    "EFF_WEIGHTS = 'imagenet'\n",
    "\n",
    "OUT_BASENAME = 'features_256d_' + BACKBONE\n",
    "CSV_PATH = os.path.join(OUT_DIR, f'{OUT_BASENAME}.csv')\n",
    "PARQUET_PATH = os.path.join(OUT_DIR, f'{OUT_BASENAME}.parquet')\n",
    "META_JSON = os.path.join(OUT_DIR, f'{OUT_BASENAME}_meta.json')\n",
    "\n",
    "\n",
    "def build_custom_cnn(num_classes: int, input_shape=(224, 224, 3)):\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # Block 1\n",
    "    x = Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    # Block 2\n",
    "    x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    # Block 3\n",
    "    x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D(name='gap', dtype='float32')(x)\n",
    "    penultimate = Dense(256, activation='relu', dtype='float32', name='feature_dense')(x)  \n",
    "    x = Dropout(0.5)(penultimate)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='logits')(x)\n",
    "\n",
    "    cls_model = Model(inputs, outputs, name='custom_cnn')\n",
    "    feat_model = Model(inputs, penultimate, name='custom_cnn_feature_extractor')\n",
    "    return cls_model, feat_model\n",
    "\n",
    "\n",
    "def build_efficientnet_feature_model(output_dim=256, input_shape=(224, 224, 3), weights='imagenet'):\n",
    "    \n",
    "    base = EfficientNetB0(include_top=False, weights=weights, input_shape=input_shape)\n",
    "    inputs = base.input\n",
    "    x = base.output\n",
    "    \n",
    "    x = GlobalAveragePooling2D(name='gap', dtype='float32')(x)\n",
    "    penultimate = Dense(output_dim, activation='relu', dtype='float32', name='feature_dense')(x) \n",
    "    feat_model = Model(inputs, penultimate, name='efficientnet_feature_extractor')\n",
    "    return feat_model\n",
    "\n",
    "\n",
    "\n",
    "if BACKBONE == 'custom':\n",
    "    cls_model, feature_model = build_custom_cnn(num_classes=len(class_dirs), input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    if CUSTOM_WEIGHTS_PATH and os.path.exists(CUSTOM_WEIGHTS_PATH):\n",
    "        try:\n",
    "            \n",
    "            cls_model.load_weights(CUSTOM_WEIGHTS_PATH, by_name=True, skip_mismatch=True)\n",
    "            print(f\"Loaded custom CNN weights from: {CUSTOM_WEIGHTS_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load custom weights: {e}\\nProceeding with random init (features will be weak).\")\n",
    "    preprocess_fn = lambda x: tf.cast(x, tf.float32) / 255.0\n",
    "else:\n",
    "    feature_model = build_efficientnet_feature_model(\n",
    "        output_dim=256, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), weights=EFF_WEIGHTS\n",
    "    )\n",
    "    preprocess_fn = eff_preprocess  \n",
    "\n",
    "records = []\n",
    "for cls in class_dirs:\n",
    "    folder = os.path.join(data_root, cls)\n",
    "    files = sorted(\n",
    "        glob.glob(os.path.join(folder, '*.jpg')) +\n",
    "        glob.glob(os.path.join(folder, '*.jpeg')) +\n",
    "        glob.glob(os.path.join(folder, '*.png'))\n",
    "    )\n",
    "    for fp in files:\n",
    "        records.append((fp, cls, class_indices[cls]))\n",
    "\n",
    "if not records:\n",
    "    raise RuntimeError(f\"No images found under {data_root} (searched *.jpg, *.jpeg, *.png).\")\n",
    "\n",
    "paths = [r[0] for r in records]\n",
    "labels = [r[2] for r in records]\n",
    "fnames = [os.path.basename(r[0]) for r in records]\n",
    "N = len(paths)\n",
    "print(f\"Found {N} images across {len(class_dirs)} classes.\")\n",
    "\n",
    "\n",
    "def load_and_preprocess(path, label, fname):\n",
    "    img_bytes = tf.io.read_file(path)\n",
    "   \n",
    "    img = tf.image.decode_image(img_bytes, channels=3, expand_animations=False)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, IMG_SIZE, method='bilinear', antialias=True)\n",
    "    img = preprocess_fn(img)\n",
    "    return img, label, fname\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((paths, labels, fnames))\n",
    "ds = ds.map(load_and_preprocess, num_parallel_calls=NUM_WORKERS)\n",
    "ds = ds.batch(BATCH_SIZE).prefetch(NUM_WORKERS)\n",
    "\n",
    "all_feats = []\n",
    "all_labels = []\n",
    "all_fnames = []\n",
    "\n",
    "num_batches = math.ceil(N / BATCH_SIZE)\n",
    "for batch_imgs, batch_labels, batch_names in tqdm(ds, total=num_batches, desc=\"Extracting\"):\n",
    "    \n",
    "    feats = feature_model(batch_imgs, training=False)  \n",
    "    \n",
    "    feats = tf.cast(feats, tf.float32)\n",
    "    all_feats.append(feats.numpy())\n",
    "    all_labels.extend(batch_labels.numpy().tolist())\n",
    "    all_fnames.extend(batch_names.numpy().astype(str).tolist())\n",
    "\n",
    "features = np.vstack(all_feats)  # [N, 256]\n",
    "assert features.shape[0] == N, \"Feature count mismatch\"\n",
    "\n",
    "df = pd.DataFrame(features, columns=[f'f{i:03d}' for i in range(features.shape[1])])\n",
    "df['class_idx'] = all_labels\n",
    "df['label'] = [index_to_class[i] for i in all_labels]\n",
    "df['filename'] = all_fnames\n",
    "\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "try:\n",
    "    df.to_parquet(PARQUET_PATH, index=False)\n",
    "except Exception as e:\n",
    "    print(f\"Parquet save failed ({e}); CSV still saved.\")\n",
    "\n",
    "with open(META_JSON, 'w') as f:\n",
    "    json.dump({\n",
    "        'img_size': IMG_SIZE,\n",
    "        'backbone': BACKBONE,\n",
    "        'feature_dim': int(features.shape[1]),\n",
    "        'class_indices': class_indices,\n",
    "        'num_images': int(features.shape[0]),\n",
    "        'data_root': data_root,\n",
    "        'mixed_precision': bool(USE_MIXED_PRECISION),\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"Saved CSV: {CSV_PATH}\")\n",
    "if os.path.exists(PARQUET_PATH):\n",
    "    print(f\"Saved Parquet: {PARQUET_PATH}\")\n",
    "print(f\"Saved meta: {META_JSON}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacea59",
   "metadata": {},
   "source": [
    "### ML on custom feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3630c08",
   "metadata": {},
   "source": [
    "#### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f4544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved artifacts to: D:\\Research\\Custom CNN\\Without Augmented\\XGB_Custom\n",
      "Best VAL acc: 0.7545\n",
      "Final TEST acc: 0.7198\n",
      "Search CSV: D:\\Research\\Custom CNN\\Without Augmented\\XGB_Custom\\xgb_custom_val_search_results.csv\n",
      "Scaler: D:\\Research\\Custom CNN\\Without Augmented\\XGB_Custom\\xgb_custom_scaler.joblib\n",
      "Val-best model: D:\\Research\\Custom CNN\\Without Augmented\\XGB_Custom\\xgb_custom_valbest.json\n",
      "Final model (train+val): D:\\Research\\Custom CNN\\Without Augmented\\XGB_Custom\\xgb_custom_final_trainval.json\n",
      "Report JSON: D:\\Research\\Custom CNN\\Without Augmented\\XGB_Custom\\xgb_custom_report.json\n"
     ]
    }
   ],
   "source": [
    "import os, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):  return int(obj)\n",
    "        if isinstance(obj, np.floating): return float(obj)\n",
    "        if isinstance(obj, np.ndarray):  return obj.tolist()\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "BASE_DIR   = r'D:\\Research\\Custom CNN\\Without Augmented'\n",
    "CSV_PATH   = r'D:\\Research\\Custom CNN\\Without Augmented\\features_256d_custom.csv'\n",
    "OUT_DIR    = os.path.join(BASE_DIR, \"XGB_Custom\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "REPORT_OUT     = os.path.join(OUT_DIR, \"xgb_custom_report.json\")\n",
    "MODEL_VAL_BEST = os.path.join(OUT_DIR, \"xgb_custom_valbest.json\")       \n",
    "MODEL_FINAL    = os.path.join(OUT_DIR, \"xgb_custom_final_trainval.json\")\n",
    "SCALER_PATH    = os.path.join(OUT_DIR, \"xgb_custom_scaler.joblib\")\n",
    "SEARCH_CSV     = os.path.join(OUT_DIR, \"xgb_custom_val_search_results.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "feat_cols = [c for c in df.columns if c.startswith(\"f\") and c[1:].isdigit()]\n",
    "if not feat_cols:\n",
    "    raise ValueError(\"No feature columns found with names like f0..f255\")\n",
    "\n",
    "X = df[feat_cols].values.astype(np.float32)\n",
    "y = df[\"class_idx\"].values.astype(np.int64)\n",
    "\n",
    "if \"label\" in df.columns:\n",
    "    class_map = df.sort_values(\"class_idx\")[[\"class_idx\",\"label\"]].drop_duplicates()\n",
    "    class_names = class_map.set_index(\"class_idx\")[\"label\"].reindex(sorted(class_map[\"class_idx\"])).tolist()\n",
    "else:\n",
    "    class_names = [str(i) for i in sorted(np.unique(y))]\n",
    "\n",
    "n_classes = int(len(np.unique(y)))\n",
    "rng = 42\n",
    "\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=rng\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.125, stratify=y_trainval, random_state=rng\n",
    ")\n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_s, label=y_train)\n",
    "dval   = xgb.DMatrix(X_val_s,   label=y_val)\n",
    "dtrainval = xgb.DMatrix(np.vstack([X_train_s, X_val_s]), label=np.concatenate([y_train, y_val]))\n",
    "dtest  = xgb.DMatrix(X_test_s,  label=y_test)\n",
    "\n",
    "\n",
    "def make_params(**p):\n",
    "    return {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": n_classes,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"eval_metric\": [\"mlogloss\",\"merror\"],\n",
    "        \"seed\": rng,\n",
    "        \"eta\": p.get(\"learning_rate\", 0.06),\n",
    "        \"max_depth\": p.get(\"max_depth\", 4),\n",
    "        \"min_child_weight\": p.get(\"min_child_weight\", 1),\n",
    "        \"subsample\": p.get(\"subsample\", 1.0),\n",
    "        \"colsample_bytree\": p.get(\"colsample_bytree\", 1.0),\n",
    "        \"alpha\": p.get(\"reg_alpha\", 0.0),\n",
    "        \"lambda\": p.get(\"reg_lambda\", 1.0),\n",
    "        \"gamma\": p.get(\"gamma\", 0.0),\n",
    "    }\n",
    "\n",
    "def predict_proba_booster(booster, dm):\n",
    "    \n",
    "    ntree_limit = getattr(booster, \"best_ntree_limit\", None)\n",
    "    if ntree_limit is not None and ntree_limit > 0:\n",
    "        proba = booster.predict(dm, ntree_limit=ntree_limit)\n",
    "    else:\n",
    "        best_it = getattr(booster, \"best_iteration\", None)\n",
    "        if best_it is not None:\n",
    "            proba = booster.predict(dm, iteration_range=(0, best_it + 1))\n",
    "        else:\n",
    "            proba = booster.predict(dm)\n",
    "    return proba\n",
    "\n",
    "def evaluate_with_reports(dm, y_true, proba, prefix):\n",
    "    y_pred = np.argmax(proba, axis=1)\n",
    "\n",
    "    acc   = accuracy_score(y_true, y_pred)\n",
    "    f1m   = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    f1w   = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    precm = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    precw = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "    recm  = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    recw  = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    \n",
    "    rep = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "    pd.DataFrame(rep).transpose().to_csv(os.path.join(OUT_DIR, f\"{prefix}_classification_report.csv\"))\n",
    "\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    pd.DataFrame(cm, index=class_names, columns=class_names).to_csv(os.path.join(OUT_DIR, f\"{prefix}_confusion_matrix.csv\"))\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title(f\"Confusion Matrix — {prefix}\")\n",
    "    plt.colorbar()\n",
    "    ticks = np.arange(len(class_names))\n",
    "    plt.xticks(ticks, class_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(ticks, class_names)\n",
    "    th = cm.max() / 2 if cm.max() > 0 else 0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > th else \"black\")\n",
    "    plt.tight_layout(); plt.ylabel(\"True\"); plt.xlabel(\"Pred\")\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_confusion_matrix.png\"), dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    metrics_extra = {}\n",
    "    if n_classes > 1:\n",
    "        y_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "        fpr, tpr, roc_auc, prec, rec, ap = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "        for c in range(n_classes):\n",
    "            fpr[c], tpr[c], _ = roc_curve(y_bin[:, c], proba[:, c])\n",
    "            roc_auc[c] = auc(fpr[c], tpr[c])\n",
    "            prec[c], rec[c], _ = precision_recall_curve(y_bin[:, c], proba[:, c])\n",
    "            ap[c] = average_precision_score(y_bin[:, c], proba[:, c])\n",
    "\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_bin.ravel(), proba.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "        prec[\"micro\"], rec[\"micro\"], _ = precision_recall_curve(y_bin.ravel(), proba.ravel())\n",
    "        ap[\"micro\"] = average_precision_score(y_bin, proba, average=\"micro\")\n",
    "\n",
    "        all_fpr = np.unique(np.concatenate([fpr[c] for c in range(n_classes)]))\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for c in range(n_classes):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[c], tpr[c])\n",
    "        mean_tpr /= n_classes\n",
    "        roc_auc[\"macro\"] = auc(all_fpr, mean_tpr)\n",
    "        ap[\"macro\"] = float(np.mean([ap[c] for c in range(n_classes)]))\n",
    "\n",
    "        \n",
    "        rows = []\n",
    "        for key in list(range(n_classes)) + [\"micro\"]:\n",
    "            for xi, yi in zip(fpr[key], tpr[key]):\n",
    "                rows.append({\"curve\": f\"ROC_{key}\", \"fpr\": float(xi), \"tpr\": float(yi)})\n",
    "        for xi, yi in zip(all_fpr, mean_tpr):\n",
    "            rows.append({\"curve\": \"ROC_macro\", \"fpr\": float(xi), \"tpr\": float(yi)})\n",
    "        pd.DataFrame(rows).to_csv(os.path.join(OUT_DIR, f\"{prefix}_roc_points.csv\"), index=False)\n",
    "\n",
    "        rows = []\n",
    "        for key in list(range(n_classes)) + [\"micro\"]:\n",
    "            for pi, ri in zip(prec[key], rec[key]):\n",
    "                rows.append({\"curve\": f\"PR_{key}\", \"precision\": float(pi), \"recall\": float(ri)})\n",
    "        pd.DataFrame(rows).to_csv(os.path.join(OUT_DIR, f\"{prefix}_pr_points.csv\"), index=False)\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(7,6))\n",
    "        for c in range(n_classes):\n",
    "            plt.plot(fpr[c], tpr[c], lw=1.2, label=f\"{class_names[c]} (AUC={roc_auc[c]:.3f})\")\n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"], lw=2, linestyle=\"--\", label=f\"micro (AUC={roc_auc['micro']:.3f})\")\n",
    "        plt.plot([0,1],[0,1],\"k--\", lw=1)\n",
    "        plt.xlim([0,1]); plt.ylim([0,1.05])\n",
    "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC — {prefix}\")\n",
    "        plt.legend(loc=\"lower right\", fontsize=8)\n",
    "        plt.tight_layout(); plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_roc_curves.png\"), dpi=160); plt.close()\n",
    "\n",
    "        plt.figure(figsize=(7,6))\n",
    "        for c in range(n_classes):\n",
    "            plt.plot(rec[c], prec[c], lw=1.2, label=f\"{class_names[c]} (AP={ap[c]:.3f})\")\n",
    "        plt.plot(rec[\"micro\"], prec[\"micro\"], lw=2, linestyle=\"--\", label=f\"micro (AP={ap['micro']:.3f})\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR — {prefix}\")\n",
    "        plt.legend(loc=\"lower left\", fontsize=8)\n",
    "        plt.tight_layout(); plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_pr_curves.png\"), dpi=160); plt.close()\n",
    "\n",
    "        metrics_extra = {\n",
    "            \"roc_auc_per_class\": {class_names[c]: float(roc_auc[c]) for c in range(n_classes)},\n",
    "            \"roc_auc_micro\": float(roc_auc[\"micro\"]),\n",
    "            \"roc_auc_macro\": float(roc_auc[\"macro\"]),\n",
    "            \"ap_per_class\": {class_names[c]: float(ap[c]) for c in range(n_classes)},\n",
    "            \"ap_micro\": float(ap[\"micro\"]),\n",
    "            \"ap_macro\": float(ap[\"macro\"]),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": float(acc),\n",
    "        \"f1_macro\": float(f1m),\n",
    "        \"f1_weighted\": float(f1w),\n",
    "        \"precision_macro\": float(precm),\n",
    "        \"precision_weighted\": float(precw),\n",
    "        \"recall_macro\": float(recm),\n",
    "        \"recall_weighted\": float(recw),\n",
    "        **metrics_extra\n",
    "    }\n",
    "\n",
    "PARAMS = {\n",
    "    \"learning_rate\":    [0.03, 0.06],\n",
    "    \"max_depth\":        [3, 4, 5],\n",
    "    \"min_child_weight\": [1, 3],\n",
    "    \"subsample\":        [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"reg_alpha\":        [0.0, 1e-3],\n",
    "    \"reg_lambda\":       [1.0],\n",
    "    \"gamma\":            [0.0],\n",
    "}\n",
    "BASE_N_ESTIMATORS = 2000\n",
    "EARLY_STOP_ROUNDS = 50\n",
    "\n",
    "keys = list(PARAMS.keys())\n",
    "grid = [dict(zip(keys, vals)) for vals in product(*[PARAMS[k] for k in keys])]\n",
    "\n",
    "search_rows = []\n",
    "best = {\"acc\": -1.0, \"params\": None, \"booster\": None, \"best_round\": None}\n",
    "\n",
    "for p in grid:\n",
    "    params = make_params(**p)\n",
    "    booster = xgb.train(\n",
    "        params, dtrain, num_boost_round=BASE_N_ESTIMATORS,\n",
    "        evals=[(dval, \"val\")],\n",
    "        early_stopping_rounds=EARLY_STOP_ROUNDS,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    val_proba = predict_proba_booster(booster, dval)\n",
    "    val_pred  = np.argmax(val_proba, axis=1)\n",
    "    acc = accuracy_score(y_val, val_pred)\n",
    "    f1m = f1_score(y_val, val_pred, average=\"macro\")\n",
    "\n",
    "    best_it = getattr(booster, \"best_iteration\", None)\n",
    "    if best_it is None:\n",
    "        bntl = getattr(booster, \"best_ntree_limit\", BASE_N_ESTIMATORS)\n",
    "        best_it = int(bntl) - 1\n",
    "\n",
    "    search_rows.append({**p, \"best_iteration\": int(best_it), \"val_accuracy\": float(acc), \"val_f1_macro\": float(f1m)})\n",
    "    if acc > best[\"acc\"]:\n",
    "        best = {\"acc\": acc, \"params\": p, \"booster\": booster, \"best_round\": int(best_it)}\n",
    "\n",
    "pd.DataFrame(search_rows).sort_values([\"val_accuracy\",\"val_f1_macro\"], ascending=False).to_csv(SEARCH_CSV, index=False)\n",
    "best[\"booster\"].save_model(MODEL_VAL_BEST)\n",
    "\n",
    "\n",
    "val_proba = predict_proba_booster(best[\"booster\"], dval)\n",
    "val_summary = evaluate_with_reports(dval, y_val, val_proba, prefix=\"val_xgb_custom\")\n",
    "\n",
    "\n",
    "best_round_count = int(best[\"best_round\"]) + 1  \n",
    "final_params = make_params(**best[\"params\"])\n",
    "final_booster = xgb.train(\n",
    "    final_params, dtrainval, num_boost_round=best_round_count,\n",
    "    evals=[(dtest, \"test\")],  \n",
    "    verbose_eval=False\n",
    ")\n",
    "final_booster.save_model(MODEL_FINAL)\n",
    "\n",
    "test_proba = final_booster.predict(dtest)  \n",
    "test_summary = evaluate_with_reports(dtest, y_test, test_proba, prefix=\"test_xgb_custom\")\n",
    "\n",
    "\n",
    "report = {\n",
    "    \"split_sizes\": {\"train\": int(X_train.shape[0]), \"val\": int(X_val.shape[0]), \"test\": int(X_test.shape[0])},\n",
    "    \"val_search_best_params\": best[\"params\"],\n",
    "    \"val_best_round\": int(best[\"best_round\"]),\n",
    "    \"val_metrics\": val_summary,\n",
    "    \"test_metrics\": test_summary,\n",
    "    \"classes\": class_names,\n",
    "    \"artifacts\": {\n",
    "        \"search_csv\": SEARCH_CSV,\n",
    "        \"scaler\": SCALER_PATH,\n",
    "        \"val_model\": MODEL_VAL_BEST,\n",
    "        \"final_model\": MODEL_FINAL\n",
    "    }\n",
    "}\n",
    "with open(REPORT_OUT, \"w\") as f:\n",
    "    json.dump(report, f, indent=2, cls=NpEncoder)\n",
    "\n",
    "print(\"\\nSaved artifacts to:\", OUT_DIR)\n",
    "print(\"Best VAL acc:\", f\"{val_summary['accuracy']:.4f}\")\n",
    "print(\"Final TEST acc:\", f\"{test_summary['accuracy']:.4f}\")\n",
    "print(\"Search CSV:\", SEARCH_CSV)\n",
    "print(\"Scaler:\", SCALER_PATH)\n",
    "print(\"Val-best model:\", MODEL_VAL_BEST)\n",
    "print(\"Final model (train+val):\", MODEL_FINAL)\n",
    "print(\"Report JSON:\", REPORT_OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc7cff",
   "metadata": {},
   "source": [
    "#### SVM    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a073cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved artifacts to: D:\\Research\\Custom CNN\\Without Augmented\\SVM\n",
      "Best VAL acc: 0.8136\n",
      "Final TEST acc: 0.7813\n",
      "Report: D:\\Research\\Custom CNN\\Without Augmented\\SVM\\svm_report.json\n"
     ]
    }
   ],
   "source": [
    "import os, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "import joblib\n",
    "\n",
    "BASE_DIR   = r'D:\\Research\\Custom CNN\\Without Augmented'\n",
    "CSV_PATH   = r'D:\\Research\\Custom CNN\\Without Augmented\\features_256d_custom.csv'\n",
    "OUT_DIR    = os.path.join(BASE_DIR, \"SVM\") \n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "REPORT_OUT = os.path.join(OUT_DIR, \"svm_report.json\")\n",
    "MODEL_VAL_BEST = os.path.join(OUT_DIR, \"svm_valbest.joblib\")\n",
    "MODEL_FINAL    = os.path.join(OUT_DIR, \"svm_final_trainval.joblib\")\n",
    "SEARCH_CSV     = os.path.join(OUT_DIR, \"svm_val_search_results.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "feat_cols = [c for c in df.columns if c.startswith(\"f\") and c[1:].isdigit()]\n",
    "X = df[feat_cols].values.astype(np.float32)\n",
    "y = df[\"class_idx\"].values.astype(np.int64)\n",
    "\n",
    "class_map = df.sort_values(\"class_idx\")[[\"class_idx\",\"label\"]].drop_duplicates()\n",
    "class_names = class_map.set_index(\"class_idx\")[\"label\"].reindex(sorted(class_map[\"class_idx\"])).tolist()\n",
    "n_classes = len(np.unique(y))\n",
    "rng = 42\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=rng\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.125, stratify=y_trainval, random_state=rng\n",
    ")\n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "def make_svm(C, gamma):\n",
    "    \n",
    "    return SVC(kernel=\"rbf\", C=C, gamma=gamma, probability=True, random_state=rng)\n",
    "\n",
    "C_LIST     = np.logspace(-2, 3, 12)     \n",
    "GAMMA_LIST = np.logspace(-5, 1, 13)    \n",
    "\n",
    "rows, best = [], {\"acc\": -1, \"params\": None, \"model\": None}\n",
    "for C in C_LIST:\n",
    "    for g in GAMMA_LIST:\n",
    "        model = make_svm(C, g)\n",
    "        model.fit(X_train_s, y_train)\n",
    "        yv_pred = model.predict(X_val_s)\n",
    "        acc = accuracy_score(y_val, yv_pred)\n",
    "        f1m = f1_score(y_val, yv_pred, average=\"macro\")\n",
    "        rows.append({\"C\": C, \"gamma\": g, \"val_accuracy\": acc, \"val_f1_macro\": f1m})\n",
    "        if acc > best[\"acc\"]:\n",
    "            best.update({\"acc\": acc, \"params\": {\"C\": float(C), \"gamma\": float(g)}, \"model\": model})\n",
    "\n",
    "pd.DataFrame(rows).sort_values([\"val_accuracy\",\"val_f1_macro\"], ascending=False).to_csv(SEARCH_CSV, index=False)\n",
    "joblib.dump({\"scaler\": scaler, \"model\": best[\"model\"]}, MODEL_VAL_BEST)\n",
    "\n",
    "\n",
    "def save_confmat_and_reports(Xs, y_true, model, prefix):\n",
    "    y_proba = model.predict_proba(Xs)\n",
    "    y_pred  = y_proba.argmax(1)\n",
    "\n",
    "    acc   = accuracy_score(y_true, y_pred)\n",
    "    f1m   = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    f1w   = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    precm = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    precw = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "    recm  = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    recw  = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    pd.DataFrame(classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "                 ).transpose().to_csv(os.path.join(OUT_DIR, f\"{prefix}_classification_report.csv\"))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    pd.DataFrame(cm, index=class_names, columns=class_names).to_csv(os.path.join(OUT_DIR, f\"{prefix}_confusion_matrix.csv\"))\n",
    "    plt.figure(figsize=(6,5)); plt.imshow(cm, interpolation='nearest'); plt.title(f\"Confusion Matrix — {prefix}\")\n",
    "    plt.colorbar(); ticks=np.arange(len(class_names))\n",
    "    plt.xticks(ticks, class_names, rotation=45, ha=\"right\"); plt.yticks(ticks, class_names)\n",
    "    th=cm.max()/2\n",
    "    for i in range(cm.shape[0]):\n",
    "      for j in range(cm.shape[1]):\n",
    "        plt.text(j,i,str(cm[i,j]),ha=\"center\",va=\"center\",color=\"white\" if cm[i,j]>th else \"black\")\n",
    "    plt.tight_layout(); plt.ylabel(\"True\"); plt.xlabel(\"Pred\")\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_confusion_matrix.png\"), dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "    metrics_extra = {}\n",
    "    if n_classes > 1:\n",
    "        y_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "        fpr, tpr, roc_auc, prec, rec, ap = {}, {}, {}, {}, {}, {}\n",
    "        for c in range(n_classes):\n",
    "            fpr[c], tpr[c], _ = roc_curve(y_bin[:, c], y_proba[:, c]); roc_auc[c] = auc(fpr[c], tpr[c])\n",
    "            prec[c], rec[c], _ = precision_recall_curve(y_bin[:, c], y_proba[:, c]); ap[c] = average_precision_score(y_bin[:, c], y_proba[:, c])\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_bin.ravel(), y_proba.ravel()); roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "        prec[\"micro\"], rec[\"micro\"], _ = precision_recall_curve(y_bin.ravel(), y_proba.ravel()); ap[\"micro\"] = average_precision_score(y_bin, y_proba, average=\"micro\")\n",
    "        all_fpr = np.unique(np.concatenate([fpr[c] for c in range(n_classes)])); mean_tpr = np.zeros_like(all_fpr)\n",
    "        for c in range(n_classes): mean_tpr += np.interp(all_fpr, fpr[c], tpr[c])\n",
    "        mean_tpr /= n_classes; roc_auc[\"macro\"] = auc(all_fpr, mean_tpr); ap[\"macro\"] = np.mean([ap[c] for c in range(n_classes)])\n",
    "        rows = []; \n",
    "        for key in list(range(n_classes)) + [\"micro\"]:\n",
    "            for xi, yi in zip(fpr[key], tpr[key]): rows.append({\"curve\": f\"ROC_{key}\", \"fpr\": float(xi), \"tpr\": float(yi)})\n",
    "        for xi, yi in zip(all_fpr, mean_tpr): rows.append({\"curve\": \"ROC_macro\", \"fpr\": float(xi), \"tpr\": float(yi)})\n",
    "        pd.DataFrame(rows).to_csv(os.path.join(OUT_DIR, f\"{prefix}_roc_points.csv\"), index=False)\n",
    "        rows = []\n",
    "        for key in list(range(n_classes)) + [\"micro\"]:\n",
    "            for pi, ri in zip(prec[key], rec[key]): rows.append({\"curve\": f\"PR_{key}\", \"precision\": float(pi), \"recall\": float(ri)})\n",
    "        pd.DataFrame(rows).to_csv(os.path.join(OUT_DIR, f\"{prefix}_pr_points.csv\"), index=False)\n",
    "\n",
    "        plt.figure(figsize=(7,6))\n",
    "        for c in range(n_classes): plt.plot(fpr[c], tpr[c], lw=1.2, label=f\"{class_names[c]} (AUC={roc_auc[c]:.3f})\")\n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"], lw=2, linestyle=\"--\", label=f\"micro (AUC={roc_auc['micro']:.3f})\")\n",
    "        plt.plot([0,1],[0,1],\"k--\", lw=1); plt.xlim([0,1]); plt.ylim([0,1.05])\n",
    "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC — {prefix}\")\n",
    "        plt.legend(loc=\"lower right\", fontsize=8); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_roc_curves.png\"), dpi=160); plt.close()\n",
    "\n",
    "        plt.figure(figsize=(7,6))\n",
    "        for c in range(n_classes): plt.plot(rec[c], prec[c], lw=1.2, label=f\"{class_names[c]} (AP={ap[c]:.3f})\")\n",
    "        plt.plot(rec[\"micro\"], rec[\"micro\"], lw=2, linestyle=\"--\", label=f\"micro (AP={ap['micro']:.3f})\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR — {prefix}\")\n",
    "        plt.legend(loc=\"lower left\", fontsize=8); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_pr_curves.png\"), dpi=160); plt.close()\n",
    "\n",
    "        metrics_extra = {\n",
    "            \"roc_auc_per_class\": {class_names[c]: float(roc_auc[c]) for c in range(n_classes)},\n",
    "            \"roc_auc_micro\": float(roc_auc[\"micro\"]),\n",
    "            \"roc_auc_macro\": float(roc_auc[\"macro\"]),\n",
    "            \"ap_per_class\": {class_names[c]: float(ap[c]) for c in range(n_classes)},\n",
    "            \"ap_micro\": float(ap[\"micro\"]),\n",
    "            \"ap_macro\": float(ap[\"macro\"]),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": float(acc),\n",
    "        \"f1_macro\": float(f1m),\n",
    "        \"f1_weighted\": float(f1w),\n",
    "        \"precision_macro\": float(precm),\n",
    "        \"precision_weighted\": float(precw),\n",
    "        \"recall_macro\": float(recm),\n",
    "        \"recall_weighted\": float(recw),\n",
    "        **metrics_extra\n",
    "    }\n",
    "\n",
    "val_summary = save_confmat_and_reports(X_val_s, y_val, best[\"model\"], prefix=\"val_svm\")\n",
    "joblib.dump({\"scaler\": scaler, \"model\": best[\"model\"]}, MODEL_VAL_BEST)\n",
    "\n",
    "p = best[\"params\"]\n",
    "final_model = make_svm(p[\"C\"], p[\"gamma\"])\n",
    "final_model.fit(np.vstack([X_train_s, X_val_s]), np.concatenate([y_train, y_val]))\n",
    "joblib.dump({\"scaler\": scaler, \"model\": final_model}, MODEL_FINAL)\n",
    "\n",
    "test_summary = save_confmat_and_reports(X_test_s, y_test, final_model, prefix=\"test_svm\")\n",
    "\n",
    "report = {\n",
    "    \"split_sizes\": {\"train\": int(X_train.shape[0]), \"val\": int(X_val.shape[0]), \"test\": int(X_test.shape[0])},\n",
    "    \"val_search_best_params\": p,\n",
    "    \"val_metrics\": val_summary,\n",
    "    \"test_metrics\": test_summary,\n",
    "    \"classes\": class_names\n",
    "}\n",
    "with open(REPORT_OUT, \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved artifacts to:\", OUT_DIR)\n",
    "print(\"Best VAL acc:\", f\"{val_summary['accuracy']:.4f}\")\n",
    "print(\"Final TEST acc:\", f\"{test_summary['accuracy']:.4f}\")\n",
    "print(\"Report:\", REPORT_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e25c6",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cf797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNN] Found feature columns: 256\n",
      "[KNN] First 10 feature cols: ['f000', 'f001', 'f002', 'f003', 'f004', 'f005', 'f006', 'f007', 'f008', 'f009']\n",
      "[KNN] X shape: (2195, 256)\n",
      "\n",
      "[KNN] Best VAL acc: 0.7273\n",
      "[KNN] Final TEST acc: 0.6834\n",
      "[KNN] Saved to: D:\\Research\\Custom CNN\\Without Augmented\\KNN\n"
     ]
    }
   ],
   "source": [
    "import os, json, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['svg.fonttype'] = 'none'  \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "BASE_DIR   = r'D:\\Research\\Custom CNN\\Without Augmented'\n",
    "CSV_PATH   = r'D:\\Research\\Custom CNN\\Without Augmented\\features_256d_custom.csv'\n",
    "OUT_DIR    = os.path.join(BASE_DIR, \"KNN\")  \n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "rng = 42\n",
    "\n",
    "SEARCH_CSV     = os.path.join(OUT_DIR, \"knn_val_search_results.csv\")\n",
    "MODEL_VALBEST  = os.path.join(OUT_DIR, \"knn_valbest.joblib\")\n",
    "MODEL_FINAL    = os.path.join(OUT_DIR, \"knn_final_trainval.joblib\")\n",
    "SCALER_PATH    = os.path.join(OUT_DIR, \"knn_scaler.joblib\")\n",
    "REPORT_JSON    = os.path.join(OUT_DIR, \"knn_report.json\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "feat_cols = [c for c in df.columns if c.startswith(\"f\") and c[1:].isdigit()]\n",
    "if not feat_cols:\n",
    "    raise RuntimeError(\"No feature columns found like f0..f255\")\n",
    "X = df[feat_cols].values.astype(np.float32)\n",
    "y = df[\"class_idx\"].values.astype(np.int64)\n",
    "\n",
    "if \"label\" in df.columns:\n",
    "    class_map = df.sort_values(\"class_idx\")[[\"class_idx\",\"label\"]].drop_duplicates()\n",
    "    class_names = (\n",
    "        class_map.set_index(\"class_idx\")[\"label\"]\n",
    "        .reindex(sorted(class_map[\"class_idx\"]))\n",
    "        .tolist()\n",
    "    )\n",
    "else:\n",
    "    class_names = [str(i) for i in sorted(np.unique(y))]\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "print(f\"[KNN] Found feature columns: {len(feat_cols)}\")\n",
    "print(\"[KNN] First 10 feature cols:\", feat_cols[:10])\n",
    "print(\"[KNN] X shape:\", X.shape)\n",
    "\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=rng\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.125, stratify=y_trainval, random_state=rng\n",
    ")\n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "\n",
    "def save_confmat_and_curves(y_true, proba, y_pred, prefix):\n",
    "    \n",
    "    rep = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "    pd.DataFrame(rep).transpose().to_csv(os.path.join(OUT_DIR, f\"{prefix}_classification_report.csv\"))\n",
    "\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    pd.DataFrame(cm, index=class_names, columns=class_names)\\\n",
    "      .to_csv(os.path.join(OUT_DIR, f\"{prefix}_confusion_matrix.csv\"))\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title(f\"Confusion Matrix — {prefix}\")\n",
    "    plt.colorbar()\n",
    "    ticks = np.arange(len(class_names))\n",
    "    plt.xticks(ticks, class_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(ticks, class_names)\n",
    "    th = cm.max()/2 if cm.max() > 0 else 0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > th else \"black\")\n",
    "    plt.tight_layout(); plt.ylabel(\"True\"); plt.xlabel(\"Pred\")\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_confusion_matrix.png\"), dpi=160, bbox_inches=\"tight\")\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_confusion_matrix.svg\"), bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    metrics_extra = {}\n",
    "    if proba is not None and n_classes > 1:\n",
    "        y_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "        proba = np.asarray(proba)\n",
    "        fpr, tpr, roc_auc = {}, {}, {}\n",
    "        prec, rec, ap = {}, {}, {}\n",
    "\n",
    "        for c in range(n_classes):\n",
    "            fpr[c], tpr[c], _ = roc_curve(y_bin[:, c], proba[:, c])\n",
    "            roc_auc[c] = auc(fpr[c], tpr[c])\n",
    "            prec[c], rec[c], _ = precision_recall_curve(y_bin[:, c], proba[:, c])\n",
    "            ap[c] = average_precision_score(y_bin[:, c], proba[:, c])\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(7,6))\n",
    "        for c in range(n_classes):\n",
    "            plt.plot(fpr[c], tpr[c], lw=1.2, label=f\"{class_names[c]} (AUC={roc_auc[c]:.3f})\")\n",
    "        plt.plot([0,1],[0,1],\"k--\", lw=1)\n",
    "        plt.xlim([0,1]); plt.ylim([0,1.05])\n",
    "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC — {prefix}\")\n",
    "        plt.legend(loc=\"lower right\", fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_roc_curves.png\"), dpi=160)\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_roc_curves.svg\"))\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(7,6))\n",
    "        for c in range(n_classes):\n",
    "            plt.plot(rec[c], prec[c], lw=1.2, label=f\"{class_names[c]} (AP={ap[c]:.3f})\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR — {prefix}\")\n",
    "        plt.legend(loc=\"lower left\", fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_pr_curves.png\"), dpi=160)\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_pr_curves.svg\"))\n",
    "        plt.close()\n",
    "\n",
    "        metrics_extra.update({\n",
    "            \"roc_auc_per_class\": {class_names[c]: float(roc_auc[c]) for c in range(n_classes)},\n",
    "            \"ap_per_class\": {class_names[c]: float(ap[c]) for c in range(n_classes)},\n",
    "            \"roc_auc_macro\": float(np.mean(list(roc_auc.values()))),\n",
    "            \"ap_macro\": float(np.mean(list(ap.values()))),\n",
    "        })\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    f1w = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    precm = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    precw = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "    recm = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    recw = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": float(acc),\n",
    "        \"f1_macro\": float(f1m),\n",
    "        \"f1_weighted\": float(f1w),\n",
    "        \"precision_macro\": float(precm),\n",
    "        \"precision_weighted\": float(precw),\n",
    "        \"recall_macro\": float(recm),\n",
    "        \"recall_weighted\": float(recw),\n",
    "        **metrics_extra\n",
    "    }\n",
    "\n",
    "grid = {\n",
    "    \"n_neighbors\": [3, 5, 9, 15],\n",
    "    \"metric\":      [\"euclidean\", \"cosine\"],\n",
    "    \"weights\":     [\"distance\"],   \n",
    "    \"leaf_size\":   [30],\n",
    "    \"p\":           [2],            \n",
    "}\n",
    "\n",
    "def knn_from(p):\n",
    "    return KNeighborsClassifier(\n",
    "        n_neighbors=p[\"n_neighbors\"],\n",
    "        metric=p[\"metric\"],\n",
    "        weights=p[\"weights\"],\n",
    "        leaf_size=p[\"leaf_size\"],\n",
    "        p=p[\"p\"],\n",
    "        algorithm=\"auto\",          \n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "keys = list(grid.keys())\n",
    "search_rows = []\n",
    "best = {\"acc\": -1.0, \"params\": None, \"model\": None}\n",
    "\n",
    "for vals in product(*[grid[k] for k in keys]):\n",
    "    p = dict(zip(keys, vals))\n",
    "    model = knn_from(p).fit(X_train_s, y_train)\n",
    "    yv = model.predict(X_val_s)\n",
    "    acc = accuracy_score(y_val, yv)\n",
    "    f1m = f1_score(y_val, yv, average=\"macro\")\n",
    "    search_rows.append({**p, \"val_accuracy\": float(acc), \"val_f1_macro\": float(f1m)})\n",
    "    if acc > best[\"acc\"]:\n",
    "        best = {\"acc\": acc, \"params\": p, \"model\": model}\n",
    "\n",
    "pd.DataFrame(search_rows).sort_values(\n",
    "    [\"val_accuracy\",\"val_f1_macro\"], ascending=False\n",
    ").to_csv(SEARCH_CSV, index=False)\n",
    "joblib.dump({\"scaler\": scaler, \"model\": best[\"model\"]}, MODEL_VALBEST)\n",
    "\n",
    "\n",
    "yv_pred = best[\"model\"].predict(X_val_s)\n",
    "yv_prob = best[\"model\"].predict_proba(X_val_s) if hasattr(best[\"model\"], \"predict_proba\") else None\n",
    "val_summary = save_confmat_and_curves(y_val, yv_prob, yv_pred, \"val_knn_custom\")\n",
    "\n",
    "X_trv = np.vstack([X_train_s, X_val_s]); y_trv = np.concatenate([y_train, y_val])\n",
    "final_model = knn_from(best[\"params\"]).fit(X_trv, y_trv)\n",
    "joblib.dump({\"scaler\": scaler, \"model\": final_model}, MODEL_FINAL)\n",
    "\n",
    "yt_pred = final_model.predict(X_test_s)\n",
    "yt_prob = final_model.predict_proba(X_test_s) if hasattr(final_model, \"predict_proba\") else None\n",
    "test_summary = save_confmat_and_curves(y_test, yt_prob, yt_pred, \"test_knn_custom\")\n",
    "\n",
    "with open(REPORT_JSON, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"split_sizes\": {\n",
    "            \"train\": int(X_train.shape[0]),\n",
    "            \"val\":   int(X_val.shape[0]),\n",
    "            \"test\":  int(X_test.shape[0])\n",
    "        },\n",
    "        \"val_search_best_params\": best[\"params\"],\n",
    "        \"val_metrics\": val_summary,\n",
    "        \"test_metrics\": test_summary,\n",
    "        \"classes\": class_names,\n",
    "        \"features_used\": feat_cols,\n",
    "        \"artifacts\": {\n",
    "            \"search_csv\": SEARCH_CSV,\n",
    "            \"scaler\": SCALER_PATH,\n",
    "            \"val_model\": MODEL_VALBEST,\n",
    "            \"final_model\": MODEL_FINAL\n",
    "        }\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"\\n[KNN] Best VAL acc:\", f\"{best['acc']:.4f}\")\n",
    "print(\"[KNN] Final TEST acc:\", f\"{test_summary['accuracy']:.4f}\")\n",
    "print(\"[KNN] Saved to:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9158796f",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49234d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved artifacts to: D:\\Research\\Custom CNN\\Without Augmented\\RF\n",
      "Best VAL acc: 0.7091\n",
      "Final TEST acc: 0.7267\n",
      "Report: D:\\Research\\Custom CNN\\Without Augmented\\RF\\rf_report.json\n",
      "Val-best model: D:\\Research\\Custom CNN\\Without Augmented\\RF\\rf_valbest.joblib\n",
      "Final model (train+val): D:\\Research\\Custom CNN\\Without Augmented\\RF\\rf_final_trainval.joblib\n",
      "Search table: D:\\Research\\Custom CNN\\Without Augmented\\RF\\rf_val_search_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "\n",
    "BASE_DIR   = r'D:\\Research\\Custom CNN\\Without Augmented'\n",
    "CSV_PATH   = r'D:\\Research\\Custom CNN\\Without Augmented\\features_256d_custom.csv'\n",
    "OUT_DIR    = os.path.join(BASE_DIR, \"RF\") \n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "REPORT_OUT = os.path.join(OUT_DIR, \"rf_report.json\")\n",
    "MODEL_VAL_BEST = os.path.join(OUT_DIR, \"rf_valbest.joblib\")\n",
    "MODEL_FINAL    = os.path.join(OUT_DIR, \"rf_final_trainval.joblib\")\n",
    "SEARCH_CSV     = os.path.join(OUT_DIR, \"rf_val_search_results.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "feat_cols = [c for c in df.columns if c.startswith(\"f\") and c[1:].isdigit()]\n",
    "X = df[feat_cols].values.astype(np.float32)\n",
    "y = df[\"class_idx\"].values.astype(np.int64)\n",
    "\n",
    "class_map = df.sort_values(\"class_idx\")[[\"class_idx\",\"label\"]].drop_duplicates()\n",
    "class_names = class_map.set_index(\"class_idx\")[\"label\"].reindex(sorted(class_map[\"class_idx\"])).tolist()\n",
    "n_classes = len(np.unique(y))\n",
    "rng = 42\n",
    "\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=rng\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.125, stratify=y_trainval, random_state=rng\n",
    ")\n",
    "\n",
    "def make_rf(params):\n",
    "    return RandomForestClassifier(\n",
    "        random_state=rng, n_jobs=-1, oob_score=False, **params\n",
    "    )\n",
    "\n",
    "GRID = {\n",
    "    \"n_estimators\":      [300, 600, 1000],\n",
    "    \"max_depth\":         [None, 12, 20],\n",
    "    \"max_features\":      [\"sqrt\", \"log2\", 0.5],\n",
    "    \"min_samples_leaf\":  [1, 2, 4],\n",
    "    \"min_samples_split\": [2, 4, 8],\n",
    "    \"bootstrap\":         [True],\n",
    "}\n",
    "keys = list(GRID.keys())\n",
    "\n",
    "search_rows, best = [], {\"acc\": -1, \"params\": None, \"model\": None}\n",
    "for values in product(*[GRID[k] for k in keys]):\n",
    "    p = dict(zip(keys, values))\n",
    "    mdl = make_rf(p)\n",
    "    mdl.fit(X_train, y_train)\n",
    "    yv_pred = mdl.predict(X_val)\n",
    "    acc = accuracy_score(y_val, yv_pred)\n",
    "    f1m = f1_score(y_val, yv_pred, average=\"macro\")\n",
    "    search_rows.append({**p, \"val_accuracy\": acc, \"val_f1_macro\": f1m})\n",
    "    if acc > best[\"acc\"]:\n",
    "        best = {\"acc\": acc, \"params\": p, \"model\": mdl}\n",
    "\n",
    "pd.DataFrame(search_rows).sort_values([\"val_accuracy\",\"val_f1_macro\"], ascending=False)\\\n",
    "    .to_csv(SEARCH_CSV, index=False)\n",
    "joblib.dump(best[\"model\"], MODEL_VAL_BEST)\n",
    "\n",
    "\n",
    "def save_confmat_and_reports(Xs, y_true, model, prefix):\n",
    "    y_proba = model.predict_proba(Xs)\n",
    "    y_pred  = y_proba.argmax(1)\n",
    "\n",
    "    acc   = accuracy_score(y_true, y_pred)\n",
    "    f1m   = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    f1w   = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    precm = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    precw = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "    recm  = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    recw  = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    pd.DataFrame(classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "                 ).transpose().to_csv(os.path.join(OUT_DIR, f\"{prefix}_classification_report.csv\"))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    pd.DataFrame(cm, index=class_names, columns=class_names)\\\n",
    "        .to_csv(os.path.join(OUT_DIR, f\"{prefix}_confusion_matrix.csv\"))\n",
    "\n",
    "    metrics_extra = {}\n",
    "    if n_classes > 1:\n",
    "        y_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "        fpr, tpr, roc_auc, prec, rec, ap = {}, {}, {}, {}, {}, {}\n",
    "        for c in range(n_classes):\n",
    "            fpr[c], tpr[c], _ = roc_curve(y_bin[:, c], y_proba[:, c]); roc_auc[c] = auc(fpr[c], tpr[c])\n",
    "            prec[c], rec[c], _ = precision_recall_curve(y_bin[:, c], y_proba[:, c]); ap[c] = average_precision_score(y_bin[:, c], y_proba[:, c])\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_bin.ravel(), y_proba.ravel()); roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "        prec[\"micro\"], rec[\"micro\"], _ = precision_recall_curve(y_bin.ravel(), y_proba.ravel()); ap[\"micro\"] = average_precision_score(y_bin, y_proba, average=\"micro\")\n",
    "        all_fpr = np.unique(np.concatenate([fpr[c] for c in range(n_classes)])); mean_tpr = np.zeros_like(all_fpr)\n",
    "        for c in range(n_classes): mean_tpr += np.interp(all_fpr, fpr[c], tpr[c])\n",
    "        mean_tpr /= n_classes; roc_auc[\"macro\"] = auc(all_fpr, mean_tpr); ap[\"macro\"] = np.mean([ap[c] for c in range(n_classes)])\n",
    "\n",
    "        rows = []\n",
    "        for key in list(range(n_classes)) + [\"micro\"]:\n",
    "            for xi, yi in zip(fpr[key], tpr[key]):\n",
    "                rows.append({\"curve\": f\"ROC_{key}\", \"fpr\": float(xi), \"tpr\": float(yi)})\n",
    "        for xi, yi in zip(all_fpr, mean_tpr):\n",
    "            rows.append({\"curve\": \"ROC_macro\", \"fpr\": float(xi), \"tpr\": float(yi)})\n",
    "        pd.DataFrame(rows).to_csv(os.path.join(OUT_DIR, f\"{prefix}_roc_points.csv\"), index=False)\n",
    "\n",
    "        rows = []\n",
    "        for key in list(range(n_classes)) + [\"micro\"]:\n",
    "            for pi, ri in zip(prec[key], rec[key]):\n",
    "                rows.append({\"curve\": f\"PR_{key}\", \"precision\": float(pi), \"recall\": float(ri)})\n",
    "        pd.DataFrame(rows).to_csv(os.path.join(OUT_DIR, f\"{prefix}_pr_points.csv\"), index=False)\n",
    "\n",
    "        plt.figure(figsize=(7,6))\n",
    "        for c in range(n_classes): plt.plot(fpr[c], tpr[c], lw=1.2, label=f\"{class_names[c]} (AUC={roc_auc[c]:.3f})\")\n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"], lw=2, linestyle=\"--\", label=f\"micro (AUC={roc_auc['micro']:.3f})\")\n",
    "        plt.plot([0,1],[0,1],\"k--\", lw=1); plt.xlim([0,1]); plt.ylim([0,1.05])\n",
    "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC — {prefix}\")\n",
    "        plt.legend(loc=\"lower right\", fontsize=8); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_roc_curves.png\"), dpi=160); plt.close()\n",
    "\n",
    "        plt.figure(figsize=(7,6))\n",
    "        for c in range(n_classes): plt.plot(rec[c], prec[c], lw=1.2, label=f\"{class_names[c]} (AP={ap[c]:.3f})\")\n",
    "        plt.plot(rec[\"micro\"], rec[\"micro\"], lw=2, linestyle=\"--\", label=f\"micro (AP={ap['micro']:.3f})\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR — {prefix}\")\n",
    "        plt.legend(loc=\"lower left\", fontsize=8); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_pr_curves.png\"), dpi=160); plt.close()\n",
    "\n",
    "        metrics_extra = {\n",
    "            \"roc_auc_per_class\": {class_names[c]: float(roc_auc[c]) for c in range(n_classes)},\n",
    "            \"roc_auc_micro\": float(roc_auc[\"micro\"]),\n",
    "            \"roc_auc_macro\": float(roc_auc[\"macro\"]),\n",
    "            \"ap_per_class\": {class_names[c]: float(ap[c]) for c in range(n_classes)},\n",
    "            \"ap_micro\": float(ap[\"micro\"]),\n",
    "            \"ap_macro\": float(ap[\"macro\"]),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": float(acc),\n",
    "        \"f1_macro\": float(f1m),\n",
    "        \"f1_weighted\": float(f1w),\n",
    "        \"precision_macro\": float(precm),\n",
    "        \"precision_weighted\": float(precw),\n",
    "        \"recall_macro\": float(recm),\n",
    "        \"recall_weighted\": float(recw),\n",
    "        **metrics_extra\n",
    "    }\n",
    "\n",
    "val_summary = save_confmat_and_reports(X_val, y_val, best[\"model\"], prefix=\"val_rf\")\n",
    "joblib.dump(best[\"model\"], MODEL_VAL_BEST)\n",
    "\n",
    "\n",
    "p = best[\"params\"].copy()\n",
    "final_model = make_rf(p)\n",
    "final_model.fit(np.vstack([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "joblib.dump(final_model, MODEL_FINAL)\n",
    "\n",
    "test_summary = save_confmat_and_reports(X_test, y_test, final_model, prefix=\"test_rf\")\n",
    "\n",
    "report = {\n",
    "    \"split_sizes\": {\"train\": int(X_train.shape[0]), \"val\": int(X_val.shape[0]), \"test\": int(X_test.shape[0])},\n",
    "    \"val_search_best_params\": p,\n",
    "    \"val_metrics\": val_summary,\n",
    "    \"test_metrics\": test_summary,\n",
    "    \"classes\": class_names\n",
    "}\n",
    "with open(REPORT_OUT, \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved artifacts to:\", OUT_DIR)\n",
    "print(\"Best VAL acc:\", f\"{val_summary['accuracy']:.4f}\")\n",
    "print(\"Final TEST acc:\", f\"{test_summary['accuracy']:.4f}\")\n",
    "print(\"Report:\", REPORT_OUT)\n",
    "print(\"Val-best model:\", MODEL_VAL_BEST)\n",
    "print(\"Final model (train+val):\", MODEL_FINAL)\n",
    "print(\"Search table:\", SEARCH_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78a77d9",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a079194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved artifacts to: /kaggle/working/Customized CNN/CAT\n",
      "Best VAL acc: 0.7455\n",
      "Final TEST acc: 0.7335\n",
      "Report: /kaggle/working/Customized CNN/CAT\\cat_report.json\n",
      "Val-best model: /kaggle/working/Customized CNN/CAT\\cat_valbest.cbm\n",
      "Final model (train+val): /kaggle/working/Customized CNN/CAT\\cat_final_trainval.cbm\n",
      "Search table: /kaggle/working/Customized CNN/CAT\\cat_val_search_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "\n",
    "CSV_PATH   = r\"D:\\Research\\Custom CNN\\Without Augmented\\features_256d_custom.csv\"   \n",
    "OUT_DIR    = \"/kaggle/working/Customized CNN/CAT\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "REPORT_OUT = os.path.join(OUT_DIR, \"cat_report.json\")\n",
    "MODEL_VAL_BEST = os.path.join(OUT_DIR, \"cat_valbest.cbm\")\n",
    "MODEL_FINAL    = os.path.join(OUT_DIR, \"cat_final_trainval.cbm\")\n",
    "SEARCH_CSV     = os.path.join(OUT_DIR, \"cat_val_search_results.csv\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "feat_cols = [c for c in df.columns if c.startswith(\"f\") and c[1:].isdigit()]\n",
    "X = df[feat_cols].values.astype(np.float32)\n",
    "y = df[\"class_idx\"].values.astype(np.int64)\n",
    "\n",
    "class_map = df.sort_values(\"class_idx\")[[\"class_idx\",\"label\"]].drop_duplicates()\n",
    "class_names = class_map.set_index(\"class_idx\")[\"label\"].reindex(sorted(class_map[\"class_idx\"])).tolist()\n",
    "n_classes = len(np.unique(y))\n",
    "rng = 42\n",
    "\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=rng\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.125, stratify=y_trainval, random_state=rng\n",
    ")\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "def make_cat(params):\n",
    "    return CatBoostClassifier(\n",
    "        loss_function=\"MultiClass\",\n",
    "        eval_metric=\"MultiClass\",\n",
    "        random_seed=rng,\n",
    "        allow_writing_files=False,\n",
    "        \n",
    "        task_type=\"GPU\" if os.environ.get(\"NVIDIA_VISIBLE_DEVICES\") not in (None, \"\", \"none\") else \"CPU\",\n",
    "        **params\n",
    "    )\n",
    "\n",
    "GRID = {\n",
    "    \"iterations\":       [2000],          \n",
    "    \"learning_rate\":    [0.03, 0.06],\n",
    "    \"depth\":            [4, 5, 6],\n",
    "    \"l2_leaf_reg\":      [1.0, 3.0, 5.0],\n",
    "    \"border_count\":     [128],           \n",
    "    \"random_strength\":  [1.0, 2.0],      \n",
    "    \"bagging_temperature\": [0.0, 1.0],   \n",
    "    \"grow_policy\":      [\"SymmetricTree\"],  \n",
    "}\n",
    "\n",
    "search_rows, best = [], {\"acc\": -1, \"params\": None, \"model\": None}\n",
    "keys = list(GRID.keys())\n",
    "for values in product(*[GRID[k] for k in keys]):\n",
    "    p = dict(zip(keys, values))\n",
    "    model = make_cat(p)\n",
    "    model.fit(\n",
    "        X_train_s, y_train,\n",
    "        eval_set=(X_val_s, y_val),\n",
    "        use_best_model=True,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    yv_pred = model.predict(X_val_s).astype(int).ravel()\n",
    "    acc = accuracy_score(y_val, yv_pred)\n",
    "    f1m = f1_score(y_val, yv_pred, average=\"macro\")\n",
    "    row = {**p,\n",
    "           \"best_iteration\": int(model.get_best_iteration()),\n",
    "           \"val_accuracy\": acc,\n",
    "           \"val_f1_macro\": f1m}\n",
    "    search_rows.append(row)\n",
    "    if acc > best[\"acc\"]:\n",
    "        best = {\"acc\": acc, \"params\": p, \"model\": model}\n",
    "\n",
    "pd.DataFrame(search_rows).sort_values([\"val_accuracy\",\"val_f1_macro\"], ascending=False)\\\n",
    "    .to_csv(SEARCH_CSV, index=False)\n",
    "best[\"model\"].save_model(MODEL_VAL_BEST)\n",
    "\n",
    "def save_confmat_and_reports(Xs, y_true, model, prefix):\n",
    "    y_proba = model.predict_proba(Xs)\n",
    "    y_pred  = y_proba.argmax(1)\n",
    "\n",
    "    acc   = accuracy_score(y_true, y_pred)\n",
    "    f1m   = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    f1w   = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    precm = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    precw = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "    recm  = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    recw  = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    pd.DataFrame(\n",
    "        classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "    ).transpose().to_csv(os.path.join(OUT_DIR, f\"{prefix}_classification_report.csv\"))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    pd.DataFrame(cm, index=class_names, columns=class_names)\\\n",
    "        .to_csv(os.path.join(OUT_DIR, f\"{prefix}_confusion_matrix.csv\"))\n",
    "\n",
    "    metrics_extra = {}\n",
    "    if n_classes > 1:\n",
    "        y_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "        fpr, tpr, roc_auc, prec, rec, ap = {}, {}, {}, {}, {}, {}\n",
    "        for c in range(n_classes):\n",
    "            fpr[c], tpr[c], _ = roc_curve(y_bin[:, c], y_proba[:, c]); roc_auc[c] = auc(fpr[c], tpr[c])\n",
    "            prec[c], rec[c], _ = precision_recall_curve(y_bin[:, c], y_proba[:, c]); ap[c] = average_precision_score(y_bin[:, c], y_proba[:, c])\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_bin.ravel(), y_proba.ravel()); roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "        prec[\"micro\"], rec[\"micro\"], _ = precision_recall_curve(y_bin.ravel(), y_proba.ravel()); ap[\"micro\"] = average_precision_score(y_bin, y_proba, average=\"micro\")\n",
    "        all_fpr = np.unique(np.concatenate([fpr[c] for c in range(n_classes)])); mean_tpr = np.zeros_like(all_fpr)\n",
    "        for c in range(n_classes): mean_tpr += np.interp(all_fpr, fpr[c], tpr[c])\n",
    "        mean_tpr /= n_classes; roc_auc[\"macro\"] = auc(all_fpr, mean_tpr); ap[\"macro\"] = np.mean([ap[c] for c in range(n_classes)])\n",
    "\n",
    "        rows = []\n",
    "        for key in list(range(n_classes)) + [\"micro\"]:\n",
    "            for xi, yi in zip(fpr[key], tpr[key]):\n",
    "                rows.append({\"curve\": f\"ROC_{key}\", \"fpr\": float(xi), \"tpr\": float(yi)})\n",
    "        for xi, yi in zip(all_fpr, mean_tpr):\n",
    "            rows.append({\"curve\": \"ROC_macro\", \"fpr\": float(xi), \"tpr\": float(yi)})\n",
    "        pd.DataFrame(rows).to_csv(os.path.join(OUT_DIR, f\"{prefix}_roc_points.csv\"), index=False)\n",
    "\n",
    "        rows = []\n",
    "        for key in list(range(n_classes)) + [\"micro\"]:\n",
    "            for pi, ri in zip(prec[key], rec[key]):\n",
    "                rows.append({\"curve\": f\"PR_{key}\", \"precision\": float(pi), \"recall\": float(ri)})\n",
    "        pd.DataFrame(rows).to_csv(os.path.join(OUT_DIR, f\"{prefix}_pr_points.csv\"), index=False)\n",
    "\n",
    "        # Plots\n",
    "        plt.figure(figsize=(7,6))\n",
    "        for c in range(n_classes): plt.plot(fpr[c], tpr[c], lw=1.2, label=f\"{class_names[c]} (AUC={roc_auc[c]:.3f})\")\n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"], lw=2, linestyle=\"--\", label=f\"micro (AUC={roc_auc['micro']:.3f})\")\n",
    "        plt.plot([0,1],[0,1],\"k--\", lw=1); plt.xlim([0,1]); plt.ylim([0,1.05])\n",
    "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC — {prefix}\")\n",
    "        plt.legend(loc=\"lower right\", fontsize=8); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_roc_curves.png\"), dpi=160); plt.close()\n",
    "\n",
    "        plt.figure(figsize=(7,6))\n",
    "        for c in range(n_classes): plt.plot(rec[c], prec[c], lw=1.2, label=f\"{class_names[c]} (AP={ap[c]:.3f})\")\n",
    "        plt.plot(rec[\"micro\"], prec[\"micro\"], lw=2, linestyle=\"--\", label=f\"micro (AP={ap['micro']:.3f})\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR — {prefix}\")\n",
    "        plt.legend(loc=\"lower left\", fontsize=8); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"{prefix}_pr_curves.png\"), dpi=160); plt.close()\n",
    "\n",
    "        metrics_extra = {\n",
    "            \"roc_auc_per_class\": {class_names[c]: float(roc_auc[c]) for c in range(n_classes)},\n",
    "            \"roc_auc_micro\": float(roc_auc[\"micro\"]),\n",
    "            \"roc_auc_macro\": float(roc_auc[\"macro\"]),\n",
    "            \"ap_per_class\": {class_names[c]: float(ap[c]) for c in range(n_classes)},\n",
    "            \"ap_micro\": float(ap[\"micro\"]),\n",
    "            \"ap_macro\": float(ap[\"macro\"]),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": float(acc),\n",
    "        \"f1_macro\": float(f1m),\n",
    "        \"f1_weighted\": float(f1w),\n",
    "        \"precision_macro\": float(precm),\n",
    "        \"precision_weighted\": float(precw),\n",
    "        \"recall_macro\": float(recm),\n",
    "        \"recall_weighted\": float(recw),\n",
    "        **metrics_extra\n",
    "    }\n",
    "\n",
    "val_summary = save_confmat_and_reports(X_val_s, y_val, best[\"model\"], prefix=\"val_cat\")\n",
    "best[\"model\"].save_model(MODEL_VAL_BEST)\n",
    "\n",
    "p = best[\"params\"].copy()\n",
    "final_model = make_cat(p)\n",
    "final_model.fit(\n",
    "    scaler.transform(np.vstack([X_train, X_val])),\n",
    "    np.concatenate([y_train, y_val]),\n",
    "    eval_set=(X_val_s, y_val),\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False\n",
    ")\n",
    "final_model.save_model(MODEL_FINAL)\n",
    "\n",
    "test_summary = save_confmat_and_reports(X_test_s, y_test, final_model, prefix=\"test_cat\")\n",
    "\n",
    "report = {\n",
    "    \"split_sizes\": {\"train\": int(X_train.shape[0]), \"val\": int(X_val.shape[0]), \"test\": int(X_test.shape[0])},\n",
    "    \"val_search_best_params\": p,\n",
    "    \"val_metrics\": val_summary,\n",
    "    \"test_metrics\": test_summary,\n",
    "    \"classes\": class_names\n",
    "}\n",
    "with open(REPORT_OUT, \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "joblib.dump(scaler, os.path.join(OUT_DIR, \"standard_scaler.joblib\"))\n",
    "\n",
    "print(\"\\nSaved artifacts to:\", OUT_DIR)\n",
    "print(\"Best VAL acc:\", f\"{val_summary['accuracy']:.4f}\")\n",
    "print(\"Final TEST acc:\", f\"{test_summary['accuracy']:.4f}\")\n",
    "print(\"Report:\", REPORT_OUT)\n",
    "print(\"Val-best model:\", MODEL_VAL_BEST)\n",
    "print(\"Final model (train+val):\", MODEL_FINAL)\n",
    "print(\"Search table:\", SEARCH_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858191d9",
   "metadata": {},
   "source": [
    "#### Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc862dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 1536, 'val': 220, 'test': 439}\n",
      "[WARN] Load failed for xgb @ D:\\Research\\Custom CNN\\Without Augmented\\XGB\\xgb_final_trainval.joblib: [Errno 2] No such file or directory: 'D:\\\\Research\\\\Custom CNN\\\\Without Augmented\\\\XGB\\\\xgb_final_trainval.joblib'\n",
      "[WARN] CatBoost load failed: catboost/libs/model/model_import_interface.h:19: Model file doesn't exist: D:\\Research\\Custom CNN\\Without Augmented\\CAT\\cat_final_trainval.cbm\n",
      "Loaded bases: ['rf', 'svm', 'lr', 'knn']\n",
      "All base names: ['et_in', 'knn', 'knn5_euc_in', 'lda_shrink_in', 'linsvc_platt_in', 'lr', 'lr_in', 'rf', 'rf_in', 'ridge_in', 'svm']\n",
      "Fold 1 done.\n",
      "Fold 2 done.\n",
      "Fold 3 done.\n",
      "Fold 4 done.\n",
      "Fold 5 done.\n",
      "Temperature scaling done.\n",
      "Meta candidates (VAL -logloss↑):\n",
      "  meta_cat   score=-0.000607 params={}\n",
      "  meta_xgb   score=-0.001631 params={}\n",
      "  meta_logreg score=-0.259692 params={'C': 2.0}\n",
      "  meta_logreg score=-0.265484 params={'C': 1.0}\n",
      "  meta_logreg score=-0.275525 params={'C': 0.5}\n",
      "\n",
      "WINNER(meta): meta_cat score=-0.000607 params={}\n",
      "VAL — meta(meta_cat): acc=1.0000, logloss=0.000560\n",
      "\n",
      "WINNER (256-D): blend  acc=0.7267, f1_macro=0.7113\n",
      "\n",
      "Saved winner-only 256-D artifacts to: D:\\Research\\Custom CNN\\Without Augmented\\Ensemble_256D\n",
      "Winner JSON: D:\\Research\\Custom CNN\\Without Augmented\\Ensemble_256D\\winner_report_256d.json\n"
     ]
    }
   ],
   "source": [
    "import os, json, joblib, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, classification_report, confusion_matrix, log_loss,\n",
    "    roc_curve, auc, precision_recall_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "rng = 42\n",
    "np.random.seed(rng)\n",
    "\n",
    "\n",
    "BASE_DIR  = r'D:\\Research\\Custom CNN\\Without Augmented'\n",
    "CSV_PATH  = os.path.join(BASE_DIR, 'features_256d_custom.csv')  \n",
    "OUT_DIR   = os.path.join(BASE_DIR, 'Ensemble_256D')\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_PATHS = {\n",
    "    \"rf\":  os.path.join(BASE_DIR, r\"RF\\rf_final_trainval.joblib\"),\n",
    "    \"svm\": os.path.join(BASE_DIR, r\"SVM\\svm_final_trainval.joblib\"),\n",
    "    \"xgb\": os.path.join(BASE_DIR, r\"XGB\\xgb_final_trainval.joblib\"),\n",
    "    \"lr\":  os.path.join(BASE_DIR, r\"LR\\logreg_sgd_final_trainval.joblib\"),\n",
    "    \"knn\": os.path.join(BASE_DIR, r\"KNN\\knn_final_trainval.joblib\"),\n",
    "    \n",
    "    \"cat\": os.path.join(BASE_DIR, r\"CAT\\cat_final_trainval.cbm\"),\n",
    "}\n",
    "REPORT_JSON = os.path.join(OUT_DIR, \"winner_report_256d.json\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "feat_cols = [c for c in df.columns if c.startswith(\"f\") and c[1:].isdigit()]\n",
    "if not feat_cols:\n",
    "    raise RuntimeError(\"No 256-D feature columns like f0..f255 found.\")\n",
    "feat_cols = sorted(feat_cols, key=lambda c: int(c[1:]))\n",
    "\n",
    "X_all = df[feat_cols].values.astype(np.float32)\n",
    "y_all = df[\"class_idx\"].values.astype(int)\n",
    "\n",
    "classes = (\n",
    "    df.sort_values(\"class_idx\")[[\"class_idx\",\"label\"]]\n",
    "      .drop_duplicates().sort_values(\"class_idx\")[\"label\"].tolist()\n",
    "    if \"label\" in df.columns else [str(i) for i in sorted(df[\"class_idx\"].unique())]\n",
    ")\n",
    "n_classes = len(np.unique(y_all))\n",
    "\n",
    "X_tmp, X_test, y_tmp, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.20, stratify=y_all, random_state=rng\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.125, stratify=y_tmp, random_state=rng\n",
    ")\n",
    "print({\"train\": len(y_train), \"val\": len(y_val), \"test\": len(y_test)})\n",
    "\n",
    "\n",
    "def _row_norm(p: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    p = np.nan_to_num(p, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    p[p < 0] = 0.0\n",
    "    s = p.sum(axis=1, keepdims=True); s[s <= 0] = 1.0\n",
    "    p = p / s\n",
    "    p = np.clip(p, eps, 1.0)\n",
    "    p = p / p.sum(axis=1, keepdims=True)\n",
    "    return p\n",
    "\n",
    "def safe_log_probs(P: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    return np.log(_row_norm(P, eps))\n",
    "\n",
    "def safe_softmax(L: np.ndarray, T: float = 1.0) -> np.ndarray:\n",
    "    L = np.nan_to_num(L, nan=0.0, posinf=0.0, neginf=0.0) / max(T, 1e-6)\n",
    "    L = L - np.max(L, axis=1, keepdims=True)\n",
    "    E = np.exp(np.clip(L, -700, 700))\n",
    "    return _row_norm(E)\n",
    "\n",
    "def entropy_and_margin(P: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    p = _row_norm(P)\n",
    "    ent = -(p * np.log(p)).sum(axis=1, keepdims=True)\n",
    "    top2 = np.partition(p, -2, axis=1)[:, -2:]\n",
    "    mar = (top2[:, 1] - top2[:, 0]).reshape(-1, 1)\n",
    "    return ent, mar\n",
    "\n",
    "def cm_plot(cm, classes, title, out_png):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    t = np.arange(len(classes))\n",
    "    plt.xticks(t, classes, rotation=45, ha=\"right\"); plt.yticks(t, classes)\n",
    "    th = cm.max()/2 if cm.max() > 0 else 0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, str(cm[i,j]), ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i,j] > th else \"black\")\n",
    "    plt.tight_layout(); plt.ylabel(\"True\"); plt.xlabel(\"Pred\")\n",
    "    plt.savefig(out_png, dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "\n",
    "def load_bundle_safe(name: str, path: str):\n",
    "    try:\n",
    "        if name == \"cat\" and path.lower().endswith(\".cbm\"):\n",
    "            try:\n",
    "                from catboost import CatBoostClassifier\n",
    "                m = CatBoostClassifier()\n",
    "                m.load_model(path)\n",
    "                return m, None\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] CatBoost load failed: {e}\")\n",
    "                return None, None\n",
    "        obj = joblib.load(path)\n",
    "        if isinstance(obj, dict) and \"model\" in obj:\n",
    "            return obj[\"model\"], obj.get(\"scaler\", None)\n",
    "        return obj, None\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Load failed for {name} @ {path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def predict_logits(model, X) -> np.ndarray:\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        d = np.asarray(model.decision_function(X))\n",
    "        if d.ndim == 1:\n",
    "            d = np.vstack([-d, d]).T\n",
    "        return np.nan_to_num(d, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float64)\n",
    "    elif hasattr(model, \"predict_proba\"):\n",
    "        return safe_log_probs(np.asarray(model.predict_proba(X), dtype=np.float64))\n",
    "    else:\n",
    "        pred = model.predict(X)\n",
    "        L = np.full((X.shape[0], n_classes), -10.0, dtype=np.float64)\n",
    "        L[np.arange(X.shape[0]), pred] = 10.0\n",
    "        return L\n",
    "\n",
    "def predict_proba_safe(model, X) -> np.ndarray:\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        p = model.predict_proba(X)\n",
    "        if p.ndim == 1:  # binary fallback\n",
    "            p = np.vstack([1-p, p]).T\n",
    "        return _row_norm(np.asarray(p, dtype=np.float64))\n",
    "    else:\n",
    "        return safe_softmax(predict_logits(model, X), 1.0)\n",
    "\n",
    "def tta_probs(model, X, n=6, seed=42):\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "    Ps = []\n",
    "    for _ in range(n):\n",
    "        X_aug = X * (1.0 + rng_local.normal(0, 0.01, X.shape)) + rng_local.normal(0, 0.005, X.shape)\n",
    "        Ps.append(_row_norm(predict_proba_safe(model, X_aug)))\n",
    "    return _row_norm(np.mean(Ps, axis=0))\n",
    "\n",
    "\n",
    "loaded_models: Dict[str, object] = {}\n",
    "loaded_scalers: Dict[str, object] = {}\n",
    "for name, path in MODEL_PATHS.items():\n",
    "    m, s = load_bundle_safe(name, path)\n",
    "    if m is not None:\n",
    "        loaded_models[name] = m\n",
    "        loaded_scalers[name] = s\n",
    "print(\"Loaded bases:\", list(loaded_models.keys()))\n",
    "\n",
    "K = 5\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=rng)\n",
    "\n",
    "extra_fold_bases = [\n",
    "    (\"rf_in\",  \"std\"),\n",
    "    (\"lr_in\",  \"std\"),\n",
    "    (\"et_in\",  \"std\"),\n",
    "    (\"knn5_euc_in\", \"std\"),\n",
    "    (\"ridge_in\", \"std\"),\n",
    "    (\"linsvc_platt_in\", \"std\"),\n",
    "    (\"lda_shrink_in\", \"std\"),\n",
    "]\n",
    "all_base_names = sorted(set(list(loaded_models.keys()) + [b for b,_ in extra_fold_bases]))\n",
    "print(\"All base names:\", all_base_names)\n",
    "\n",
    "oof_logits = {b: np.zeros((len(y_train), n_classes), dtype=np.float64) for b in all_base_names}\n",
    "oof_probs  = {b: np.zeros((len(y_train), n_classes), dtype=np.float64) for b in all_base_names}\n",
    "val_logits = {b: np.zeros((len(y_val),   n_classes), dtype=np.float64) for b in all_base_names}\n",
    "val_probs  = {b: np.zeros((len(y_val),   n_classes), dtype=np.float64) for b in all_base_names}\n",
    "test_logits= {b: np.zeros((len(y_test),  n_classes), dtype=np.float64) for b in all_base_names}\n",
    "test_probs = {b: np.zeros((len(y_test),  n_classes), dtype=np.float64) for b in all_base_names}\n",
    "\n",
    "std_full = StandardScaler().fit(X_train)\n",
    "bag_counts = {b: 0 for b,_ in extra_fold_bases}\n",
    "\n",
    "def build_fold_model(tag: str):\n",
    "    if tag == \"rf_in\":\n",
    "        return RandomForestClassifier(n_estimators=600, max_features=\"sqrt\", bootstrap=True, random_state=rng, n_jobs=-1)\n",
    "    if tag == \"et_in\":\n",
    "        return ExtraTreesClassifier(n_estimators=800, max_features=\"sqrt\", bootstrap=False, random_state=rng, n_jobs=-1)\n",
    "    if tag == \"lr_in\":\n",
    "        return SGDClassifier(loss=\"log_loss\", penalty=\"l2\", alpha=1e-4, learning_rate=\"optimal\",\n",
    "                             max_iter=3500, tol=1e-4, random_state=rng, n_jobs=-1)\n",
    "    if tag == \"knn5_euc_in\":\n",
    "        return KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\", weights=\"distance\", n_jobs=-1)\n",
    "    if tag == \"ridge_in\":\n",
    "        return RidgeClassifier(alpha=1.0, random_state=rng)\n",
    "    if tag == \"linsvc_platt_in\":\n",
    "        base = LinearSVC(C=1.0, random_state=rng)\n",
    "        return CalibratedClassifierCV(estimator=base, method=\"sigmoid\", cv=3)\n",
    "    if tag == \"lda_shrink_in\":\n",
    "        return LinearDiscriminantAnalysis(solver=\"lsqr\", shrinkage=\"auto\")\n",
    "    raise ValueError(tag)\n",
    "\n",
    "for fold, (tr_idx, oof_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    Xtr, Xoo = X_train[tr_idx], X_train[oof_idx]\n",
    "    ytr, yoo = y_train[tr_idx], y_train[oof_idx]\n",
    "\n",
    "    Xtr_s, Xoo_s = std_full.transform(Xtr), std_full.transform(Xoo)\n",
    "    Xva_s, Xte_s = std_full.transform(X_val), std_full.transform(X_test)\n",
    "\n",
    "    # preloaded bases: OOF via TTA on unscaled or saved-scaler space\n",
    "    for b in loaded_models.keys():\n",
    "        model = loaded_models[b]; scaler = loaded_scalers[b]\n",
    "        Xoo_u = scaler.transform(Xoo) if scaler is not None else Xoo\n",
    "        Poo = _row_norm(tta_probs(model, Xoo_u, n=6, seed=rng+fold))\n",
    "        oof_probs[b][oof_idx]  = Poo\n",
    "        oof_logits[b][oof_idx] = safe_log_probs(Poo)\n",
    "\n",
    "    # in-fold bases\n",
    "    for tag, prep in extra_fold_bases:\n",
    "        clf = build_fold_model(tag)\n",
    "        Xtr_in = Xtr_s if prep==\"std\" else Xtr\n",
    "        Xoo_in = Xoo_s if prep==\"std\" else Xoo\n",
    "        Xva_in = Xva_s if prep==\"std\" else X_val\n",
    "        Xte_in = Xte_s if prep==\"std\" else X_test\n",
    "\n",
    "        clf.fit(Xtr_in, ytr)\n",
    "        Poo = _row_norm(predict_proba_safe(clf, Xoo_in))\n",
    "        oof_probs[tag][oof_idx]  = Poo\n",
    "        oof_logits[tag][oof_idx] = safe_log_probs(Poo)\n",
    "\n",
    "        Pva = _row_norm(predict_proba_safe(clf, Xva_in))\n",
    "        val_probs[tag]  += Pva\n",
    "        val_logits[tag] += safe_log_probs(Pva)\n",
    "\n",
    "        Pte = _row_norm(predict_proba_safe(clf, Xte_in))\n",
    "        test_probs[tag]  += Pte\n",
    "        test_logits[tag] += safe_log_probs(Pte)\n",
    "\n",
    "        bag_counts[tag] += 1\n",
    "\n",
    "    print(f\"Fold {fold} done.\")\n",
    "\n",
    "\n",
    "for tag, _ in extra_fold_bases:\n",
    "    if bag_counts[tag] > 0:\n",
    "        val_probs[tag]  = _row_norm(val_probs[tag] / bag_counts[tag])\n",
    "        val_logits[tag] = safe_log_probs(val_probs[tag])\n",
    "        test_probs[tag]  = _row_norm(test_probs[tag] / bag_counts[tag])\n",
    "        test_logits[tag] = safe_log_probs(test_probs[tag])\n",
    "\n",
    "\n",
    "for b in loaded_models.keys():\n",
    "    scaler = loaded_scalers[b]\n",
    "    Xva_u = scaler.transform(X_val) if scaler is not None else X_val\n",
    "    Xte_u = scaler.transform(X_test) if scaler is not None else X_test\n",
    "    Pva = _row_norm(tta_probs(loaded_models[b], Xva_u, n=6, seed=rng+77))\n",
    "    val_probs[b]  = Pva\n",
    "    val_logits[b] = safe_log_probs(Pva)\n",
    "    Pte = _row_norm(tta_probs(loaded_models[b], Xte_u, n=6, seed=rng+99))\n",
    "    test_probs[b]  = Pte\n",
    "    test_logits[b] = safe_log_probs(Pte)\n",
    "\n",
    "base_names = all_base_names\n",
    "for b in base_names:\n",
    "    oof_logits[b] = np.nan_to_num(oof_logits[b], nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    oof_probs[b]  = _row_norm(oof_probs[b])\n",
    "    val_probs[b]  = _row_norm(val_probs[b])\n",
    "    test_probs[b] = _row_norm(test_probs[b])\n",
    "\n",
    "\n",
    "def nll_from_logits(logits: np.ndarray, y_true: np.ndarray, T) -> float:\n",
    "    if np.isscalar(T):\n",
    "        pl = safe_softmax(logits, T)\n",
    "    else:\n",
    "        L = np.nan_to_num(logits, nan=0.0)\n",
    "        L = L - np.max(L, axis=1, keepdims=True)\n",
    "        E = np.exp(np.clip(L, -700, 700))\n",
    "        E = E / np.maximum(np.asarray(T).reshape(1, -1), 1e-6)\n",
    "        pl = _row_norm(E)\n",
    "    return log_loss(y_true, pl, labels=np.arange(n_classes))\n",
    "\n",
    "def fit_temperature_classwise(logits_val: np.ndarray, y_val: np.ndarray) -> np.ndarray:\n",
    "    Tvec = np.ones(n_classes)\n",
    "    for c in range(n_classes):\n",
    "        cand = np.linspace(0.1, 5.0, 40)\n",
    "        best_T, best = 1.0, float(\"inf\")\n",
    "        for T in cand:\n",
    "            Tv = Tvec.copy(); Tv[c] = T\n",
    "            n = nll_from_logits(logits_val, y_val, Tv)\n",
    "            if n < best: best, best_T = n, T\n",
    "        fine = np.linspace(max(0.1, best_T-0.4), min(5.0, best_T+0.4), 31)\n",
    "        for T in fine:\n",
    "            Tv = Tvec.copy(); Tv[c] = T\n",
    "            n = nll_from_logits(logits_val, y_val, Tv)\n",
    "            if n < best: best, best_T = n, T\n",
    "        Tvec[c] = best_T\n",
    "    return Tvec\n",
    "\n",
    "temperatures: Dict[str, np.ndarray] = {}\n",
    "oof_probs_cal, val_probs_cal, test_probs_cal = {}, {}, {}\n",
    "for b in base_names:\n",
    "    Tvec = fit_temperature_classwise(oof_logits[b], y_train)\n",
    "    temperatures[b] = Tvec\n",
    "\n",
    "    def apply_temp_classwise(logits: np.ndarray, Tvec: np.ndarray) -> np.ndarray:\n",
    "        L = np.nan_to_num(logits, nan=0.0)\n",
    "        L = L - np.max(L, axis=1, keepdims=True)\n",
    "        E = np.exp(np.clip(L, -700, 700))\n",
    "        E = E / np.maximum(Tvec.reshape(1,-1), 1e-6)\n",
    "        return _row_norm(E)\n",
    "\n",
    "    oof_probs_cal[b] = apply_temp_classwise(oof_logits[b], Tvec)\n",
    "    val_probs_cal[b] = apply_temp_classwise(val_logits[b], Tvec)\n",
    "    test_probs_cal[b]= apply_temp_classwise(test_logits[b], Tvec)\n",
    "\n",
    "print(\"Temperature scaling done.\")\n",
    "\n",
    "\n",
    "raw_scaler = StandardScaler().fit(X_train)\n",
    "Z_tr = raw_scaler.transform(X_train)\n",
    "Z_va = raw_scaler.transform(X_val)\n",
    "Z_te = raw_scaler.transform(X_test)\n",
    "\n",
    "eps = 1e-3\n",
    "class_means, class_invDiag = [], []\n",
    "for c in range(n_classes):\n",
    "    Zc = Z_tr[y_train==c]\n",
    "    mu = Zc.mean(0)\n",
    "    var = Zc.var(0) + eps\n",
    "    class_means.append(mu); class_invDiag.append(1.0/var)\n",
    "class_means = np.vstack(class_means); class_invDiag = np.vstack(class_invDiag)\n",
    "\n",
    "def mahalanobis_diag(Z):\n",
    "    N = Z.shape[0]; C = class_means.shape[0]\n",
    "    D = np.zeros((N, C), dtype=np.float64)\n",
    "    for c in range(C):\n",
    "        diff = Z - class_means[c]\n",
    "        D[:, c] = np.einsum('ij,ij->i', diff*class_invDiag[c], diff)\n",
    "    return np.sqrt(np.maximum(D, 0.0))\n",
    "\n",
    "D_tr_maha = mahalanobis_diag(Z_tr)\n",
    "D_va_maha = mahalanobis_diag(Z_va)\n",
    "D_te_maha = mahalanobis_diag(Z_te)\n",
    "\n",
    "\n",
    "def build_meta(prob_map: Dict[str, np.ndarray], raw_X: np.ndarray, D_maha: np.ndarray) -> np.ndarray:\n",
    "    blocks = []\n",
    "    for b in base_names:\n",
    "        P = _row_norm(prob_map[b])\n",
    "        ent, mar = entropy_and_margin(P)\n",
    "        blocks += [P, ent, mar]\n",
    "    R = raw_scaler.transform(raw_X).astype(np.float32)\n",
    "    return np.hstack(blocks + [R, D_maha])\n",
    "\n",
    "X_meta_train = build_meta(oof_probs_cal, X_train, D_tr_maha)  \n",
    "X_meta_val   = build_meta(val_probs_cal, X_val,   D_va_maha)\n",
    "X_meta_test  = build_meta(test_probs_cal, X_test, D_te_maha)\n",
    "\n",
    "\n",
    "P_mean = np.mean([oof_probs_cal[b] for b in base_names], axis=0)\n",
    "maj_pred = P_mean.argmax(axis=1)\n",
    "w_train = 1.0 + (maj_pred != y_train).astype(float)\n",
    "\n",
    "\n",
    "def eval_meta(model):\n",
    "    model.fit(X_meta_train, y_train, sample_weight=w_train)\n",
    "    P = _row_norm(model.predict_proba(X_meta_val))\n",
    "    return -log_loss(y_val, P, labels=np.arange(n_classes)), model  \n",
    "\n",
    "cands = []\n",
    "for C in [0.5, 1.0, 2.0]:\n",
    "    m = LogisticRegression(C=C, penalty=\"l2\", solver=\"lbfgs\",\n",
    "                           multi_class=\"multinomial\", max_iter=5000, n_jobs=-1, random_state=rng)\n",
    "    score, mdl = eval_meta(m); cands.append((\"meta_logreg\", score, {\"C\": C}, mdl))\n",
    "\n",
    "mxgb = XGBClassifier(\n",
    "    objective=\"multi:softprob\", num_class=n_classes, eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\", random_state=rng,\n",
    "    n_estimators=1200, max_depth=6, learning_rate=0.03, subsample=0.9, colsample_bytree=0.9,\n",
    ")\n",
    "score, mdl = eval_meta(mxgb); cands.append((\"meta_xgb\", score, {}, mdl))\n",
    "\n",
    "HAS_CAT = False\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    HAS_CAT = True\n",
    "except Exception:\n",
    "    HAS_CAT = False\n",
    "if HAS_CAT:\n",
    "    mcat = CatBoostClassifier(\n",
    "        loss_function=\"MultiClass\", eval_metric=\"MultiClass\", random_seed=rng,\n",
    "        verbose=False, iterations=1400, depth=6, learning_rate=0.06, l2_leaf_reg=3,\n",
    "        bootstrap_type=\"Bayesian\", bagging_temperature=1.0\n",
    "    )\n",
    "    score, mdl = eval_meta(mcat); cands.append((\"meta_cat\", score, {}, mdl))\n",
    "\n",
    "cands.sort(key=lambda t: t[1], reverse=True)\n",
    "best_name, best_score, best_par, best_model = cands[0]\n",
    "print(\"Meta candidates (VAL -logloss↑):\")\n",
    "for n,s,p,_ in cands: print(f\"  {n:10s} score={s:.6f} params={p}\")\n",
    "print(f\"\\nWINNER(meta): {best_name} score={best_score:.6f} params={best_par}\")\n",
    "\n",
    "# Retrain meta on TRAIN OOF\n",
    "if best_name == \"meta_logreg\":\n",
    "    meta_final = LogisticRegression(C=best_par[\"C\"], penalty=\"l2\", solver=\"lbfgs\",\n",
    "                                    multi_class=\"multinomial\", max_iter=6000, n_jobs=-1, random_state=rng)\n",
    "elif best_name == \"meta_xgb\":\n",
    "    meta_final = XGBClassifier(\n",
    "        objective=\"multi:softprob\", num_class=n_classes, eval_metric=\"mlogloss\",\n",
    "        tree_method=\"hist\", random_state=rng,\n",
    "        n_estimators=1400, max_depth=6, learning_rate=0.028, subsample=0.9, colsample_bytree=0.9,\n",
    "    )\n",
    "else:\n",
    "    if HAS_CAT:\n",
    "        from catboost import CatBoostClassifier\n",
    "        meta_final = CatBoostClassifier(\n",
    "            loss_function=\"MultiClass\", eval_metric=\"MultiClass\", random_seed=rng,\n",
    "            verbose=False, iterations=1600, depth=6, learning_rate=0.055, l2_leaf_reg=3,\n",
    "            bootstrap_type=\"Bayesian\", bagging_temperature=1.0\n",
    "        )\n",
    "    else:\n",
    "        meta_final = LogisticRegression(C=1.5, penalty=\"l2\", solver=\"lbfgs\",\n",
    "                                        multi_class=\"multinomial\", max_iter=6000, n_jobs=-1, random_state=rng)\n",
    "meta_final.fit(X_meta_train, y_train, sample_weight=w_train)\n",
    "\n",
    "# Evaluate meta and a per-class blend\n",
    "P_val_meta = _row_norm(meta_final.predict_proba(X_meta_val))\n",
    "y_val_pred = P_val_meta.argmax(axis=1)\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "val_ll  = log_loss(y_val, P_val_meta, labels=np.arange(n_classes))\n",
    "print(f\"VAL — meta({best_name}): acc={val_acc:.4f}, logloss={val_ll:.6f}\")\n",
    "\n",
    "P_test_meta = _row_norm(meta_final.predict_proba(X_meta_test))\n",
    "y_test_pred = P_test_meta.argmax(axis=1)\n",
    "test_acc_meta = accuracy_score(y_test, y_test_pred)\n",
    "test_f1_meta  = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "\n",
    "P_list_oof = [oof_probs_cal[b] for b in base_names]\n",
    "P_list_te  = [test_probs_cal[b] for b in base_names]\n",
    "B = len(base_names)\n",
    "\n",
    "def project_cols_simplex(W: np.ndarray) -> np.ndarray:\n",
    "    W = np.maximum(W, 0); s = W.sum(axis=0, keepdims=True); s[s<=0]=1.0; return W/s\n",
    "\n",
    "def blend_logloss(P_list, W, y_true, lam=5e-4):\n",
    "    N, C = P_list[0].shape\n",
    "    P = np.zeros((N, C), dtype=np.float64)\n",
    "    for b in range(B): P += P_list[b] * W[b, :]\n",
    "    P = _row_norm(P)\n",
    "    return log_loss(y_true, P, labels=np.arange(C)) + lam*(W**2).sum()\n",
    "\n",
    "def search_W(P_list, y_true, trials=2500, refine=600, lam=5e-4):\n",
    "    C = P_list[0].shape[1]\n",
    "    W = np.ones((B, C))/B\n",
    "    bestW, best = W.copy(), blend_logloss(P_list, W, y_true, lam)\n",
    "    for _ in range(trials):\n",
    "        W0 = np.random.dirichlet(alpha=np.ones(B), size=C).T\n",
    "        L0 = blend_logloss(P_list, W0, y_true, lam)\n",
    "        if L0 < best: best, bestW = L0, W0\n",
    "    W = bestW\n",
    "    for _ in range(refine):\n",
    "        Wp = project_cols_simplex(W + np.random.normal(0, 0.02, size=W.shape))\n",
    "        Lp = blend_logloss(P_list, Wp, y_true, lam)\n",
    "        if Lp < best: best, W = Lp, Wp\n",
    "    return W, best\n",
    "\n",
    "W_oof, _ = search_W(P_list_oof, y_train)\n",
    "\n",
    "def apply_W(P_list, W):\n",
    "    N, C = P_list[0].shape\n",
    "    P = np.zeros((N, C), dtype=np.float64)\n",
    "    for b in range(B): P += P_list[b] * W[b, :]\n",
    "    return _row_norm(P)\n",
    "\n",
    "P_test_blend = apply_W(P_list_te, W_oof)\n",
    "y_test_blend = P_test_blend.argmax(axis=1)\n",
    "acc_blend = accuracy_score(y_test, y_test_blend)\n",
    "f1_blend  = f1_score(y_test, y_test_blend, average=\"macro\")\n",
    "\n",
    "cands_test = [\n",
    "    (\"meta\",  test_acc_meta, test_f1_meta, y_test_pred, P_test_meta),\n",
    "    (\"blend\", acc_blend,     f1_blend,     y_test_blend, P_test_blend),\n",
    "]\n",
    "cands_test.sort(key=lambda x: (x[1], -log_loss(y_test, x[4], labels=np.arange(n_classes))), reverse=True)\n",
    "winner_name, winner_acc, winner_f1, winner_pred, winner_P = cands_test[0]\n",
    "print(f\"\\nWINNER (256-D): {winner_name}  acc={winner_acc:.4f}, f1_macro={winner_f1:.4f}\")\n",
    "\n",
    "\n",
    "cm  = confusion_matrix(y_test, winner_pred)\n",
    "pd.DataFrame(cm, index=classes, columns=classes).to_csv(os.path.join(OUT_DIR, f\"cm_test_{winner_name}.csv\"))\n",
    "cm_plot(cm, classes, f\"Confusion — {winner_name.upper()} (TEST, 256-D)\", os.path.join(OUT_DIR, f\"cm_test_{winner_name}.png\"))\n",
    "\n",
    "rep = classification_report(y_test, winner_pred, target_names=classes, output_dict=True)\n",
    "\n",
    "Y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "fpr_dict, tpr_dict, roc_auc_dict = {}, {}, {}\n",
    "plt.figure(figsize=(7,6))\n",
    "for c in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(Y_test_bin[:, c], winner_P[:, c])\n",
    "    auc_c = auc(fpr, tpr)\n",
    "    fpr_dict[c], tpr_dict[c], roc_auc_dict[c] = fpr, tpr, auc_c\n",
    "    plt.plot(fpr, tpr, label=f\"{classes[c]} (AUC={auc_c:.3f})\")\n",
    "fpr_micro, tpr_micro, _ = roc_curve(Y_TEST_BIN := Y_test_bin.ravel(), P_FLAT := winner_P.ravel())\n",
    "auc_micro = auc(fpr_micro, tpr_micro)\n",
    "plt.plot(fpr_micro, tpr_micro, linestyle=\"--\", label=f\"micro (AUC={auc_micro:.3f})\")\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC — {winner_name.upper()} (256-D)\")\n",
    "plt.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, f\"roc_{winner_name}.png\"), dpi=160); plt.close()\n",
    "\n",
    "roc_rows = []\n",
    "for c in range(n_classes):\n",
    "    for i in range(len(fpr_dict[c])):\n",
    "        roc_rows.append({\"class_idx\": c, \"class\": classes[c], \"fpr\": float(fpr_dict[c][i]), \"tpr\": float(tpr_dict[c][i])})\n",
    "pd.DataFrame(roc_rows).to_csv(os.path.join(OUT_DIR, f\"roc_points_{winner_name}.csv\"), index=False)\n",
    "\n",
    "pr_dict = {}\n",
    "plt.figure(figsize=(7,6))\n",
    "for c in range(n_classes):\n",
    "    prec, rec, _ = precision_recall_curve(Y_test_bin[:, c], winner_P[:, c])\n",
    "    pr_dict[c] = (prec, rec)\n",
    "    plt.plot(rec, prec, label=f\"{classes[c]}\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR — {winner_name.upper()} (256-D)\")\n",
    "plt.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, f\"pr_{winner_name}.png\"), dpi=160); plt.close()\n",
    "\n",
    "pr_rows = []\n",
    "for c in range(n_classes):\n",
    "    prec, rec = pr_dict[c]\n",
    "    for i in range(len(prec)):\n",
    "        pr_rows.append({\"class_idx\": c, \"class\": classes[c], \"recall\": float(rec[i]), \"precision\": float(prec[i])})\n",
    "pd.DataFrame(pr_rows).to_csv(os.path.join(OUT_DIR, f\"pr_points_{winner_name}.csv\"), index=False)\n",
    "\n",
    "\n",
    "with open(REPORT_JSON, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"split_sizes\": {\"train\": int(len(y_train)), \"val\": int(len(y_val)), \"test\": int(len(y_test))},\n",
    "        \"winner\": {\n",
    "            \"name\": winner_name,\n",
    "            \"accuracy\": float(winner_acc),\n",
    "            \"f1_macro\": float(winner_f1),\n",
    "            \"classification_report\": rep,\n",
    "            \"roc_auc_micro\": float(auc_micro)\n",
    "        },\n",
    "        \"classes\": classes[:],\n",
    "        \"feature_columns_preview\": feat_cols[:10] + ([\"...\"] if len(feat_cols) > 10 else [])\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved winner-only 256-D artifacts to:\", OUT_DIR)\n",
    "print(\"Winner JSON:\", REPORT_JSON)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
