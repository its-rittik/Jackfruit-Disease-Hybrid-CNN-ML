{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3562b75",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a99f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2195 files belonging to 6 classes.\n",
      "Using 1756 files for training.\n",
      "Found 2195 files belonging to 6 classes.\n",
      "Using 439 files for validation.\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30s/step - accuracy: 0.4000 - loss: 1.5029 \n",
      "Epoch 1: val_accuracy improved from None to 0.00000, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m896s\u001b[0m 32s/step - accuracy: 0.4710 - loss: 1.3375 - val_accuracy: 0.0000e+00 - val_loss: 1.8443 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38s/step - accuracy: 0.5564 - loss: 1.0974 \n",
      "Epoch 2: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1101s\u001b[0m 39s/step - accuracy: 0.5598 - loss: 1.0944 - val_accuracy: 0.0000e+00 - val_loss: 2.2533 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - accuracy: 0.5485 - loss: 1.0704 \n",
      "Epoch 3: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m820s\u001b[0m 29s/step - accuracy: 0.5598 - loss: 1.0576 - val_accuracy: 0.0000e+00 - val_loss: 2.6459 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34s/step - accuracy: 0.5556 - loss: 1.0180 \n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m995s\u001b[0m 35s/step - accuracy: 0.5746 - loss: 0.9994 - val_accuracy: 0.0000e+00 - val_loss: 2.3192 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34s/step - accuracy: 0.5985 - loss: 0.9571 \n",
      "Epoch 5: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1005s\u001b[0m 36s/step - accuracy: 0.6071 - loss: 0.9218 - val_accuracy: 0.0000e+00 - val_loss: 2.6478 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67s/step - accuracy: 0.6364 - loss: 0.8892  \n",
      "Epoch 6: val_accuracy improved from 0.00000 to 0.02278, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1925s\u001b[0m 69s/step - accuracy: 0.6327 - loss: 0.8855 - val_accuracy: 0.0228 - val_loss: 2.2996 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32s/step - accuracy: 0.6605 - loss: 0.8882 \n",
      "Epoch 7: val_accuracy did not improve from 0.02278\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m966s\u001b[0m 33s/step - accuracy: 0.6669 - loss: 0.8668 - val_accuracy: 0.0000e+00 - val_loss: 2.4697 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34s/step - accuracy: 0.6438 - loss: 0.8605 \n",
      "Epoch 8: val_accuracy did not improve from 0.02278\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m995s\u001b[0m 36s/step - accuracy: 0.6595 - loss: 0.8329 - val_accuracy: 0.0000e+00 - val_loss: 1.9400 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42s/step - accuracy: 0.6655 - loss: 0.8256 \n",
      "Epoch 9: val_accuracy improved from 0.02278 to 0.09567, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1214s\u001b[0m 43s/step - accuracy: 0.6697 - loss: 0.8077 - val_accuracy: 0.0957 - val_loss: 1.7326 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - accuracy: 0.6904 - loss: 0.7841 \n",
      "Epoch 10: val_accuracy did not improve from 0.09567\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m865s\u001b[0m 31s/step - accuracy: 0.6771 - loss: 0.7966 - val_accuracy: 0.0023 - val_loss: 2.1117 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24s/step - accuracy: 0.6859 - loss: 0.7830 \n",
      "Epoch 11: val_accuracy improved from 0.09567 to 0.12301, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 25s/step - accuracy: 0.6828 - loss: 0.7822 - val_accuracy: 0.1230 - val_loss: 1.7574 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - accuracy: 0.6921 - loss: 0.7717 \n",
      "Epoch 12: val_accuracy did not improve from 0.12301\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m850s\u001b[0m 30s/step - accuracy: 0.6936 - loss: 0.7601 - val_accuracy: 0.1002 - val_loss: 3.3227 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23s/step - accuracy: 0.6897 - loss: 0.7392 \n",
      "Epoch 13: val_accuracy improved from 0.12301 to 0.23690, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 24s/step - accuracy: 0.6959 - loss: 0.7302 - val_accuracy: 0.2369 - val_loss: 3.0242 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32s/step - accuracy: 0.7006 - loss: 0.7380 \n",
      "Epoch 14: val_accuracy improved from 0.23690 to 0.26196, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m916s\u001b[0m 33s/step - accuracy: 0.7187 - loss: 0.7061 - val_accuracy: 0.2620 - val_loss: 2.0583 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25s/step - accuracy: 0.7032 - loss: 0.7259 \n",
      "Epoch 15: val_accuracy did not improve from 0.26196\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 27s/step - accuracy: 0.7067 - loss: 0.7225 - val_accuracy: 0.0888 - val_loss: 2.5628 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - accuracy: 0.7310 - loss: 0.6927 \n",
      "Epoch 16: val_accuracy did not improve from 0.26196\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m777s\u001b[0m 28s/step - accuracy: 0.7289 - loss: 0.6874 - val_accuracy: 0.1868 - val_loss: 2.6413 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32s/step - accuracy: 0.7209 - loss: 0.7101 \n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.26196\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m952s\u001b[0m 33s/step - accuracy: 0.7289 - loss: 0.6892 - val_accuracy: 0.0137 - val_loss: 5.4309 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - accuracy: 0.7254 - loss: 0.6785 \n",
      "Epoch 18: val_accuracy did not improve from 0.26196\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m871s\u001b[0m 31s/step - accuracy: 0.7403 - loss: 0.6472 - val_accuracy: 0.1686 - val_loss: 2.8915 - learning_rate: 2.5000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.7619 - loss: 0.5815 \n",
      "Epoch 19: val_accuracy did not improve from 0.26196\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 20s/step - accuracy: 0.7603 - loss: 0.5897 - val_accuracy: 0.2210 - val_loss: 2.5648 - learning_rate: 2.5000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48s/step - accuracy: 0.7699 - loss: 0.5739 \n",
      "Epoch 20: val_accuracy improved from 0.26196 to 0.49431, saving model to D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_best.weights.h5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1343s\u001b[0m 49s/step - accuracy: 0.7699 - loss: 0.5734 - val_accuracy: 0.4943 - val_loss: 1.5470 - learning_rate: 2.5000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping final epoch weights (no improvement over last OR no checkpoint).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full model (.h5): D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_full.h5\n",
      "Saved weights (.weights.h5): D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn.weights.h5\n",
      "Saved feature extractor (.h5): D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_feature_extractor.h5\n",
      "Saved meta: D:\\Research\\Custom CNN\\Without Augmented\\custom_cnn_meta.json\n",
      "WARNING:tensorflow:From c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Rittik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "os.environ.pop(\"XLA_FLAGS\", None)\n",
    "tf.config.set_soft_device_placement(True)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(2)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(2)\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "for g in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "        print(\"Mixed precision ON\")\n",
    "    except Exception:\n",
    "        print(\"Mixed precision not enabled; continuing in float32.\")\n",
    "\n",
    "\n",
    "OUT_DIR   = r'D:\\Research\\Custom CNN\\Without Augmented'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "data_root = r'D:\\Research\\Custom CNN\\Without Augmented\\Original Image'  # class subfolders\n",
    "IMG_SIZE  = (224, 224)\n",
    "BATCH     = 64\n",
    "VAL_SPLIT = 0.2\n",
    "SEED      = 42\n",
    "\n",
    "FULL_MODEL_H5      = os.path.join(OUT_DIR, \"custom_cnn_full.h5\")\n",
    "WEIGHTS_H5         = os.path.join(OUT_DIR, \"custom_cnn.weights.h5\")\n",
    "FEAT_EXTRACTOR_H5  = os.path.join(OUT_DIR, \"custom_cnn_feature_extractor.h5\")\n",
    "META_JSON          = os.path.join(OUT_DIR, \"custom_cnn_meta.json\")\n",
    "CKPT_WEIGHTS       = os.path.join(OUT_DIR, \"custom_cnn_best.weights.h5\")\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_root, labels=\"inferred\", label_mode=\"int\",\n",
    "    image_size=IMG_SIZE, batch_size=BATCH,\n",
    "    validation_split=VAL_SPLIT, subset=\"training\", seed=SEED, shuffle=True\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_root, labels=\"inferred\", label_mode=\"int\",\n",
    "    image_size=IMG_SIZE, batch_size=BATCH,\n",
    "    validation_split=VAL_SPLIT, subset=\"validation\", seed=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "def norm(x, y):\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    return x, y\n",
    "\n",
    "train_ds = train_ds.map(norm, num_parallel_calls=2).prefetch(2)\n",
    "val_ds   = val_ds.map(norm,   num_parallel_calls=2).prefetch(2)\n",
    "\n",
    "\n",
    "aug = tf.keras.Sequential([\n",
    "    L.RandomFlip(\"horizontal\"),\n",
    "    L.RandomRotation(0.05),\n",
    "    L.RandomZoom(0.1),\n",
    "], name=\"aug\")\n",
    "\n",
    "\n",
    "def conv_block(x, filters, k=3, s=1, p=\"same\"):\n",
    "    x = L.Conv2D(filters, k, strides=s, padding=p, use_bias=False)(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_custom_cnn(input_shape=(224,224,3), n_classes=3, feature_dim=256, dropout=0.5):\n",
    "    inputs = L.Input(shape=input_shape)\n",
    "    x = aug(inputs)\n",
    "\n",
    "    x = conv_block(x, 32); x = conv_block(x, 32); x = L.MaxPooling2D(2)(x)\n",
    "    x = conv_block(x, 64); x = conv_block(x, 64); x = L.MaxPooling2D(2)(x)\n",
    "    x = conv_block(x, 128); x = conv_block(x, 128); x = L.MaxPooling2D(2)(x)\n",
    "\n",
    "    gap = L.GlobalAveragePooling2D()(x)\n",
    "    se  = L.Dense(128//4, activation=\"relu\", dtype=\"float32\")(gap)\n",
    "    se  = L.Dense(128, activation=\"sigmoid\", dtype=\"float32\")(se)\n",
    "    x   = L.Multiply()([x, L.Reshape((1,1,128))(se)])\n",
    "\n",
    "    x = L.GlobalAveragePooling2D(name=\"gap\")(x)\n",
    "    feat = L.Dense(feature_dim, activation=\"relu\", name=\"feature_dense\", dtype=\"float32\")(x)\n",
    "    x = L.Dropout(dropout)(feat)\n",
    "    outputs = L.Dense(n_classes, activation=\"softmax\", name=\"logits\", dtype=\"float32\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"custom_cnn\")\n",
    "    feat_model = Model(inputs, feat, name=\"custom_cnn_feature_extractor\")\n",
    "    return model, feat_model\n",
    "\n",
    "model, feat_model = build_custom_cnn(\n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "    n_classes=num_classes,\n",
    "    feature_dim=256,\n",
    "    dropout=0.5\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.5, patience=3, verbose=1, min_lr=1e-6),\n",
    "    ModelCheckpoint(\n",
    "        CKPT_WEIGHTS, monitor=\"val_accuracy\",\n",
    "        save_best_only=True, save_weights_only=True, verbose=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_acc = history.history.get(\"val_accuracy\", [])\n",
    "if len(val_acc) > 0 and max(val_acc) > val_acc[-1] and os.path.exists(CKPT_WEIGHTS):\n",
    "    print(f\"Loading best weights (val_acc {max(val_acc):.4f} > last {val_acc[-1]:.4f})\")\n",
    "    model.load_weights(CKPT_WEIGHTS)\n",
    "else:\n",
    "    print(\"Keeping final epoch weights (no improvement over last OR no checkpoint).\")\n",
    "\n",
    "model.save(FULL_MODEL_H5)\n",
    "model.save_weights(WEIGHTS_H5)\n",
    "feat_model.save(FEAT_EXTRACTOR_H5)\n",
    "\n",
    "with open(META_JSON, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"img_size\": IMG_SIZE,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"class_names\": class_names,\n",
    "        \"feature_dim\": 256,\n",
    "        \"epochs_trained\": int(len(history.history.get(\"loss\", []))),\n",
    "        \"best_val_accuracy\": float(max(val_acc)) if len(val_acc) else None,\n",
    "        \"last_val_accuracy\": float(val_acc[-1]) if len(val_acc) else None,\n",
    "        \"out_dir\": OUT_DIR\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"Saved full model (.h5): {FULL_MODEL_H5}\")\n",
    "print(f\"Saved weights (.weights.h5): {WEIGHTS_H5}\")\n",
    "print(f\"Saved feature extractor (.h5): {FEAT_EXTRACTOR_H5}\")\n",
    "print(f\"Saved meta: {META_JSON}\")\n",
    "\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695b4c1",
   "metadata": {},
   "source": [
    "#### Feature extraction pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load custom weights: `by_name` only supports loading legacy '.h5' or '.hdf5' files. Received: custom_cnn.weights.h5\n",
      "Proceeding with random init (features will be weak).\n",
      "Found 2195 images across 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 35/35 [01:07<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet save failed (Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\n",
      "A suitable version of pyarrow or fastparquet is required for parquet support.\n",
      "Trying to import the above resulted in these errors:\n",
      " - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n",
      " - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.); CSV still saved.\n",
      "Saved CSV: D:\\Research\\Custom CNN\\Without Augmented\\features_256d_custom.csv\n",
      "Saved meta: D:\\Research\\Custom CNN\\Without Augmented\\features_256d_custom_meta.json\n"
     ]
    }
   ],
   "source": [
    "import os, json, glob, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, BatchNormalization, Dropout,\n",
    "    GlobalAveragePooling2D, Dense\n",
    ")\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "try:\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "except Exception:\n",
    "    pass  \n",
    "\n",
    "\n",
    "USE_MIXED_PRECISION = True and bool(tf.config.list_physical_devices('GPU'))\n",
    "if USE_MIXED_PRECISION:\n",
    "    try:\n",
    "        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "        print(\"Mixed precision enabled (global_policy = 'mixed_float16').\")\n",
    "    except Exception:\n",
    "        print(\"Could not enable mixed precision; proceeding in float32.\")\n",
    "\n",
    "\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "data_root = r'D:\\Research\\Custom CNN\\Without Augmented\\Original Image'\n",
    "\n",
    "OUT_DIR = r'D:\\Research\\Custom CNN\\Without Augmented'\n",
    "\n",
    "\n",
    "class_dirs = sorted([d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d))])\n",
    "if not class_dirs:\n",
    "    raise RuntimeError(f\"No class folders found under {data_root}\")\n",
    "\n",
    "class_indices = {c: i for i, c in enumerate(class_dirs)}\n",
    "index_to_class = {i: c for c, i in class_indices.items()}\n",
    "\n",
    "BACKBONE = 'custom'\n",
    "\n",
    "CUSTOM_WEIGHTS_PATH = 'custom_cnn.weights.h5'\n",
    "EFF_WEIGHTS = 'imagenet'\n",
    "\n",
    "OUT_BASENAME = 'features_256d_' + BACKBONE\n",
    "CSV_PATH = os.path.join(OUT_DIR, f'{OUT_BASENAME}.csv')\n",
    "PARQUET_PATH = os.path.join(OUT_DIR, f'{OUT_BASENAME}.parquet')\n",
    "META_JSON = os.path.join(OUT_DIR, f'{OUT_BASENAME}_meta.json')\n",
    "\n",
    "\n",
    "def build_custom_cnn(num_classes: int, input_shape=(224, 224, 3)):\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # Block 1\n",
    "    x = Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    # Block 2\n",
    "    x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    # Block 3\n",
    "    x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D(name='gap', dtype='float32')(x)\n",
    "    penultimate = Dense(256, activation='relu', dtype='float32', name='feature_dense')(x)  \n",
    "    x = Dropout(0.5)(penultimate)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='logits')(x)\n",
    "\n",
    "    cls_model = Model(inputs, outputs, name='custom_cnn')\n",
    "    feat_model = Model(inputs, penultimate, name='custom_cnn_feature_extractor')\n",
    "    return cls_model, feat_model\n",
    "\n",
    "\n",
    "def build_efficientnet_feature_model(output_dim=256, input_shape=(224, 224, 3), weights='imagenet'):\n",
    "    \n",
    "    base = EfficientNetB0(include_top=False, weights=weights, input_shape=input_shape)\n",
    "    inputs = base.input\n",
    "    x = base.output\n",
    "    \n",
    "    x = GlobalAveragePooling2D(name='gap', dtype='float32')(x)\n",
    "    penultimate = Dense(output_dim, activation='relu', dtype='float32', name='feature_dense')(x) \n",
    "    feat_model = Model(inputs, penultimate, name='efficientnet_feature_extractor')\n",
    "    return feat_model\n",
    "\n",
    "\n",
    "\n",
    "if BACKBONE == 'custom':\n",
    "    cls_model, feature_model = build_custom_cnn(num_classes=len(class_dirs), input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    if CUSTOM_WEIGHTS_PATH and os.path.exists(CUSTOM_WEIGHTS_PATH):\n",
    "        try:\n",
    "            \n",
    "            cls_model.load_weights(CUSTOM_WEIGHTS_PATH, by_name=True, skip_mismatch=True)\n",
    "            print(f\"Loaded custom CNN weights from: {CUSTOM_WEIGHTS_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load custom weights: {e}\\nProceeding with random init (features will be weak).\")\n",
    "    preprocess_fn = lambda x: tf.cast(x, tf.float32) / 255.0\n",
    "else:\n",
    "    feature_model = build_efficientnet_feature_model(\n",
    "        output_dim=256, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), weights=EFF_WEIGHTS\n",
    "    )\n",
    "    preprocess_fn = eff_preprocess  \n",
    "\n",
    "records = []\n",
    "for cls in class_dirs:\n",
    "    folder = os.path.join(data_root, cls)\n",
    "    files = sorted(\n",
    "        glob.glob(os.path.join(folder, '*.jpg')) +\n",
    "        glob.glob(os.path.join(folder, '*.jpeg')) +\n",
    "        glob.glob(os.path.join(folder, '*.png'))\n",
    "    )\n",
    "    for fp in files:\n",
    "        records.append((fp, cls, class_indices[cls]))\n",
    "\n",
    "if not records:\n",
    "    raise RuntimeError(f\"No images found under {data_root} (searched *.jpg, *.jpeg, *.png).\")\n",
    "\n",
    "paths = [r[0] for r in records]\n",
    "labels = [r[2] for r in records]\n",
    "fnames = [os.path.basename(r[0]) for r in records]\n",
    "N = len(paths)\n",
    "print(f\"Found {N} images across {len(class_dirs)} classes.\")\n",
    "\n",
    "\n",
    "def load_and_preprocess(path, label, fname):\n",
    "    img_bytes = tf.io.read_file(path)\n",
    "   \n",
    "    img = tf.image.decode_image(img_bytes, channels=3, expand_animations=False)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, IMG_SIZE, method='bilinear', antialias=True)\n",
    "    img = preprocess_fn(img)\n",
    "    return img, label, fname\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((paths, labels, fnames))\n",
    "ds = ds.map(load_and_preprocess, num_parallel_calls=NUM_WORKERS)\n",
    "ds = ds.batch(BATCH_SIZE).prefetch(NUM_WORKERS)\n",
    "\n",
    "all_feats = []\n",
    "all_labels = []\n",
    "all_fnames = []\n",
    "\n",
    "num_batches = math.ceil(N / BATCH_SIZE)\n",
    "for batch_imgs, batch_labels, batch_names in tqdm(ds, total=num_batches, desc=\"Extracting\"):\n",
    "    \n",
    "    feats = feature_model(batch_imgs, training=False)  \n",
    "    \n",
    "    feats = tf.cast(feats, tf.float32)\n",
    "    all_feats.append(feats.numpy())\n",
    "    all_labels.extend(batch_labels.numpy().tolist())\n",
    "    all_fnames.extend(batch_names.numpy().astype(str).tolist())\n",
    "\n",
    "features = np.vstack(all_feats)  # [N, 256]\n",
    "assert features.shape[0] == N, \"Feature count mismatch\"\n",
    "\n",
    "df = pd.DataFrame(features, columns=[f'f{i:03d}' for i in range(features.shape[1])])\n",
    "df['class_idx'] = all_labels\n",
    "df['label'] = [index_to_class[i] for i in all_labels]\n",
    "df['filename'] = all_fnames\n",
    "\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "try:\n",
    "    df.to_parquet(PARQUET_PATH, index=False)\n",
    "except Exception as e:\n",
    "    print(f\"Parquet save failed ({e}); CSV still saved.\")\n",
    "\n",
    "with open(META_JSON, 'w') as f:\n",
    "    json.dump({\n",
    "        'img_size': IMG_SIZE,\n",
    "        'backbone': BACKBONE,\n",
    "        'feature_dim': int(features.shape[1]),\n",
    "        'class_indices': class_indices,\n",
    "        'num_images': int(features.shape[0]),\n",
    "        'data_root': data_root,\n",
    "        'mixed_precision': bool(USE_MIXED_PRECISION),\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"Saved CSV: {CSV_PATH}\")\n",
    "if os.path.exists(PARQUET_PATH):\n",
    "    print(f\"Saved Parquet: {PARQUET_PATH}\")\n",
    "print(f\"Saved meta: {META_JSON}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
